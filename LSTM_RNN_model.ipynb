{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  1)The dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpickled_dataframe\n",
    "# contains Rhein river levels from 01/01/2000 to 31/12/2012\n",
    "\n",
    "df = pd.read_pickle(\"riverlevels.pandas.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455904, 15)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Andernach</th>\n",
       "      <th>Bingen</th>\n",
       "      <th>Bonn</th>\n",
       "      <th>Frankfurt Osthafen</th>\n",
       "      <th>Kalkofen Neu</th>\n",
       "      <th>Kaub</th>\n",
       "      <th>Koblenz</th>\n",
       "      <th>Koblenz Up</th>\n",
       "      <th>Mainz</th>\n",
       "      <th>Oberwinter</th>\n",
       "      <th>Oestrich</th>\n",
       "      <th>Raunheim</th>\n",
       "      <th>Rockenau Ska</th>\n",
       "      <th>Speyer</th>\n",
       "      <th>Worms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:00+00:00</th>\n",
       "      <td>617.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>652.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>459.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>522.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>557.0</td>\n",
       "      <td>345.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>426.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:15:00+00:00</th>\n",
       "      <td>616.0</td>\n",
       "      <td>373.0</td>\n",
       "      <td>651.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>515.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>345.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>425.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:30:00+00:00</th>\n",
       "      <td>615.0</td>\n",
       "      <td>373.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>314.0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>344.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>570.0</td>\n",
       "      <td>425.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:45:00+00:00</th>\n",
       "      <td>613.0</td>\n",
       "      <td>373.0</td>\n",
       "      <td>649.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>513.0</td>\n",
       "      <td>516.0</td>\n",
       "      <td>474.0</td>\n",
       "      <td>554.0</td>\n",
       "      <td>344.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>570.0</td>\n",
       "      <td>425.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 01:00:00+00:00</th>\n",
       "      <td>612.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>647.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>457.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>509.0</td>\n",
       "      <td>474.0</td>\n",
       "      <td>553.0</td>\n",
       "      <td>344.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>570.0</td>\n",
       "      <td>425.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Andernach  Bingen   Bonn  Frankfurt Osthafen  \\\n",
       "2000-01-01 00:00:00+00:00      617.0   374.0  652.0               200.0   \n",
       "2000-01-01 00:15:00+00:00      616.0   373.0  651.0               199.0   \n",
       "2000-01-01 00:30:00+00:00      615.0   373.0  650.0               198.0   \n",
       "2000-01-01 00:45:00+00:00      613.0   373.0  649.0               199.0   \n",
       "2000-01-01 01:00:00+00:00      612.0   372.0  647.0               200.0   \n",
       "\n",
       "                           Kalkofen Neu   Kaub  Koblenz  Koblenz Up  Mainz  \\\n",
       "2000-01-01 00:00:00+00:00         315.0  459.0    517.0       522.0  475.0   \n",
       "2000-01-01 00:15:00+00:00         315.0  458.0    515.0       520.0  475.0   \n",
       "2000-01-01 00:30:00+00:00         314.0  458.0    514.0       517.0  475.0   \n",
       "2000-01-01 00:45:00+00:00         312.0  458.0    513.0       516.0  474.0   \n",
       "2000-01-01 01:00:00+00:00         311.0  457.0    512.0       509.0  474.0   \n",
       "\n",
       "                           Oberwinter  Oestrich  Raunheim  Rockenau Ska  \\\n",
       "2000-01-01 00:00:00+00:00       557.0     345.0     182.0         296.0   \n",
       "2000-01-01 00:15:00+00:00       555.0     345.0     182.0         295.0   \n",
       "2000-01-01 00:30:00+00:00       555.0     344.0     180.0         296.0   \n",
       "2000-01-01 00:45:00+00:00       554.0     344.0     179.0         296.0   \n",
       "2000-01-01 01:00:00+00:00       553.0     344.0     178.0         294.0   \n",
       "\n",
       "                           Speyer  Worms  \n",
       "2000-01-01 00:00:00+00:00   571.0  426.0  \n",
       "2000-01-01 00:15:00+00:00   571.0  425.0  \n",
       "2000-01-01 00:30:00+00:00   570.0  425.0  \n",
       "2000-01-01 00:45:00+00:00   570.0  425.0  \n",
       "2000-01-01 01:00:00+00:00   570.0  425.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Andernach</th>\n",
       "      <th>Bingen</th>\n",
       "      <th>Bonn</th>\n",
       "      <th>Frankfurt Osthafen</th>\n",
       "      <th>Kalkofen Neu</th>\n",
       "      <th>Kaub</th>\n",
       "      <th>Koblenz</th>\n",
       "      <th>Koblenz Up</th>\n",
       "      <th>Mainz</th>\n",
       "      <th>Oberwinter</th>\n",
       "      <th>Oestrich</th>\n",
       "      <th>Raunheim</th>\n",
       "      <th>Rockenau Ska</th>\n",
       "      <th>Speyer</th>\n",
       "      <th>Worms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-12-31 22:45:00+00:00</th>\n",
       "      <td>640.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>338.0</td>\n",
       "      <td>538.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>516.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>573.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>472.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-31 23:00:00+00:00</th>\n",
       "      <td>640.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>338.0</td>\n",
       "      <td>537.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>516.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>573.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>471.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-31 23:15:00+00:00</th>\n",
       "      <td>639.0</td>\n",
       "      <td>428.0</td>\n",
       "      <td>669.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>537.0</td>\n",
       "      <td>548.0</td>\n",
       "      <td>515.0</td>\n",
       "      <td>534.0</td>\n",
       "      <td>572.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>471.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-31 23:30:00+00:00</th>\n",
       "      <td>639.0</td>\n",
       "      <td>428.0</td>\n",
       "      <td>669.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>536.0</td>\n",
       "      <td>547.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>534.0</td>\n",
       "      <td>572.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>607.0</td>\n",
       "      <td>471.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-31 23:45:00+00:00</th>\n",
       "      <td>638.0</td>\n",
       "      <td>428.0</td>\n",
       "      <td>668.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>536.0</td>\n",
       "      <td>545.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>534.0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>404.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>607.0</td>\n",
       "      <td>470.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Andernach  Bingen   Bonn  Frankfurt Osthafen  \\\n",
       "2012-12-31 22:45:00+00:00      640.0   430.0  670.0               266.0   \n",
       "2012-12-31 23:00:00+00:00      640.0   430.0  670.0               266.0   \n",
       "2012-12-31 23:15:00+00:00      639.0   428.0  669.0               265.0   \n",
       "2012-12-31 23:30:00+00:00      639.0   428.0  669.0               265.0   \n",
       "2012-12-31 23:45:00+00:00      638.0   428.0  668.0               265.0   \n",
       "\n",
       "                           Kalkofen Neu   Kaub  Koblenz  Koblenz Up  Mainz  \\\n",
       "2012-12-31 22:45:00+00:00         338.0  538.0    549.0       516.0  535.0   \n",
       "2012-12-31 23:00:00+00:00         338.0  537.0    549.0       516.0  535.0   \n",
       "2012-12-31 23:15:00+00:00         337.0  537.0    548.0       515.0  534.0   \n",
       "2012-12-31 23:30:00+00:00         337.0  536.0    547.0       511.0  534.0   \n",
       "2012-12-31 23:45:00+00:00         336.0  536.0    545.0       511.0  534.0   \n",
       "\n",
       "                           Oberwinter  Oestrich  Raunheim  Rockenau Ska  \\\n",
       "2012-12-31 22:45:00+00:00       573.0     406.0     258.0         303.0   \n",
       "2012-12-31 23:00:00+00:00       573.0     405.0     258.0         303.0   \n",
       "2012-12-31 23:15:00+00:00       572.0     405.0     258.0         303.0   \n",
       "2012-12-31 23:30:00+00:00       572.0     405.0     257.0         303.0   \n",
       "2012-12-31 23:45:00+00:00       571.0     404.0     257.0         303.0   \n",
       "\n",
       "                           Speyer  Worms  \n",
       "2012-12-31 22:45:00+00:00   608.0  472.0  \n",
       "2012-12-31 23:00:00+00:00   608.0  471.0  \n",
       "2012-12-31 23:15:00+00:00   608.0  471.0  \n",
       "2012-12-31 23:30:00+00:00   607.0  471.0  \n",
       "2012-12-31 23:45:00+00:00   607.0  470.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task : predict future river levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Are there any \"nan\" values in the dataset ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Andernach</th>\n",
       "      <th>Bingen</th>\n",
       "      <th>Bonn</th>\n",
       "      <th>Frankfurt Osthafen</th>\n",
       "      <th>Kalkofen Neu</th>\n",
       "      <th>Kaub</th>\n",
       "      <th>Koblenz</th>\n",
       "      <th>Koblenz Up</th>\n",
       "      <th>Mainz</th>\n",
       "      <th>Oberwinter</th>\n",
       "      <th>Oestrich</th>\n",
       "      <th>Raunheim</th>\n",
       "      <th>Rockenau Ska</th>\n",
       "      <th>Speyer</th>\n",
       "      <th>Worms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-03-31 23:00:00+00:00</th>\n",
       "      <td>394.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>357.0</td>\n",
       "      <td>347.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>368.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Andernach  Bingen   Bonn  Frankfurt Osthafen  \\\n",
       "2008-03-31 23:00:00+00:00      394.0   252.0  424.0               222.0   \n",
       "\n",
       "                           Kalkofen Neu   Kaub  Koblenz  Koblenz Up  Mainz  \\\n",
       "2008-03-31 23:00:00+00:00         331.0  289.0    325.0       329.0  357.0   \n",
       "\n",
       "                           Oberwinter  Oestrich  Raunheim  Rockenau Ska  \\\n",
       "2008-03-31 23:00:00+00:00       347.0     238.0     199.0         274.0   \n",
       "\n",
       "                           Speyer  Worms  \n",
       "2008-03-31 23:00:00+00:00   368.0    NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2008-03-31 23:00:00+00:00'], dtype='datetime64[ns, UTC]', freq='15T')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.isnull().any(axis=1)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "230.75"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace the nan value by the average values of the two preceding and the two following values\n",
    "df['Worms']['2008-03-31 23:00:00+00:00'] = (1/4) * ( df['Worms']['2008-03-31 22:30:00+00:00'] + \n",
    "                                                    df['Worms']['2008-03-31 22:45:00+00:00'] +\n",
    "                                                    df['Worms']['2008-03-31 23:15:00+00:00'] +\n",
    "                                                    df['Worms']['2008-03-31 23:30:00+00:00'] )\n",
    "\n",
    "df['Worms']['2008-03-31 23:00:00+00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value = df.values.max()\n",
    "min_value = df.values.min()\n",
    "values_range = max_value - min_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_set(target_city, future_timesteps) :\n",
    "    \n",
    "    \"\"\"\n",
    "    future_timesteps : the timesteps I want to predict in the future\n",
    "            for example, if I want to predict 1 hour in the future then the parameter should be 4,\n",
    "            since the dataset has 4 samples per hour\n",
    "    \"\"\"\n",
    "    \n",
    "    # consider all samples except for the last \"future_timesteps\"\n",
    "    X_data = df.values[0:-future_timesteps]\n",
    "    \n",
    "    # as target for each sample we will set the respective city value \"future_timesteps\" ahead\n",
    "    df_targets = df[target_city].shift(-future_timesteps) # we shift the target_city sequence by \"future_timesteps\" ahead\n",
    "    y_data = df_targets.values[:-future_timesteps]\n",
    "    \n",
    "    # normalize values \n",
    "    X_data = ( X_data - min_value ) / ( values_range )\n",
    "    y_data = ( y_data - min_value ) / ( values_range )\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size = 0.1, random_state = 0)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_timeseries (target_city) :\n",
    "    \n",
    "    target_city_levels = df[target_city]\n",
    "    l=np.arange(target_city_levels.size)\n",
    "    %matplotlib notebook\n",
    "    plt.figure()\n",
    "    plt.plot(l,target_city_levels)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def the_model (target_city, future_timesteps) :\n",
    "    \n",
    "    # PART 1 : TUNING HYPERPARAMETERS - check 54 different models\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = get_train_test_set(target_city, future_timesteps)\n",
    "    \n",
    "    # fix dimensions to feed data into the lstm rnn\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0],1,X_train.shape[1]))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0],1,X_test.shape[1]))\n",
    "    \n",
    "    best_val_loss = 1\n",
    "\n",
    "    for lstm_units in [128,64]:\n",
    "        for hidden_dense_layers in [0,1,2]:\n",
    "            for dense_units in [64,32,16]:\n",
    "                for act_fct in ['linear', 'tanh','sigmoid']:\n",
    "\n",
    "                    model = Sequential()\n",
    "                    # input layer\n",
    "                    model.add(LSTM(units = lstm_units, return_sequences=True, input_shape = (1,15) )) \n",
    "                    # hidden dense layers\n",
    "                    if hidden_dense_layers == 1:\n",
    "                        model.add(Dense(dense_units, activation = act_fct))\n",
    "                    if hidden_dense_layers == 2:\n",
    "                        model.add(Dense(dense_units, activation = act_fct))\n",
    "                        model.add(Dense(dense_units, activation = act_fct))\n",
    "                    # output layer\n",
    "                    model.add(Dense(1, activation = 'linear'))\n",
    "\n",
    "                    model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "                    h = model.fit(X_train, y_train,\n",
    "                                  epochs = 20, batch_size = 512,\n",
    "                                validation_data = (X_test, y_test))\n",
    "                    \n",
    "                    tr_loss = h.history['loss'][-1]\n",
    "                    val_loss = h.history['val_loss'][-1]\n",
    "\n",
    "                    if val_loss < best_val_loss and abs(tr_loss - val_loss) < 0.01:\n",
    "                        best_val_loss = val_loss\n",
    "                        opt_parameters = {'lstm_units' : lstm_units,\n",
    "                                            'hidden_dense_layers' : hidden_dense_layers,\n",
    "                                            'dense_units' : dense_units,\n",
    "                                            'act_fct' : act_fct}\n",
    "                        \n",
    "    print('******************************************************************************************************************')\n",
    "    print('******************************************************************************************************************')\n",
    "    \n",
    "    print('the final model is the one with : ', opt_parameters)\n",
    "\n",
    "    # PART 2 : THE FINAL/OPTIMAL MODEL\n",
    "    \n",
    "    #construction\n",
    "    model = Sequential()\n",
    "    # input layer\n",
    "    model.add(LSTM(units = opt_parameters['lstm_units'] , return_sequences=True, input_shape = (1,15) )) \n",
    "    # hidden dense layers\n",
    "    if opt_parameters['hidden_dense_layers'] == 1:\n",
    "        model.add(Dense(opt_parameters['dense_units'], activation = act_fct))\n",
    "    if opt_parameters['hidden_dense_layers'] == 2:\n",
    "        model.add(Dense(opt_parameters['dense_units'], activation = opt_parameters['act_fct']))\n",
    "        model.add(Dense(opt_parameters['dense_units'], activation = opt_parameters['act_fct']))\n",
    "    # output layer\n",
    "    model.add(Dense(1, activation = 'linear'))\n",
    "\n",
    "    model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    #training on the whole dataset\n",
    "    h = model.fit(X_train, y_train,\n",
    "           epochs = 40, batch_size = 512,\n",
    "                 validation_data = (X_test, y_test))\n",
    "    \n",
    "    #plot the learning curve\n",
    "    %matplotlib notebook\n",
    "    plt.figure()\n",
    "    plt.plot(h.history['loss'])\n",
    "    plt.plot(h.history['val_loss'])\n",
    "    plt.legend(['train loss', 'test loss'])\n",
    "    plt.show()\n",
    "    \n",
    "    return opt_parameters, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark : We see that training the model depends on the y_data and consequently on the future time steps. This means that each time we want to make a different prediction we must train the model on different dataset.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(target_city) :\n",
    "    \n",
    "    # \n",
    "    most_recent_sample_point = df.values[-1]\n",
    "    column = df.columns.get_loc(target_city)\n",
    "    last_observed_city_level = most_recent_sample_point[column]\n",
    "    \n",
    "    # normalize\n",
    "    norm_most_recent_sample_point = (most_recent_sample_point - min_value) / ( values_range)\n",
    "    \n",
    "    # normalized prediction\n",
    "    norm_most_recent_sample_point = np.reshape(norm_most_recent_sample_point, (1,1,15))\n",
    "    norm_prediction = the_model[1].predict(norm_most_recent_sample_point)\n",
    "    \n",
    "    # un-normalized prediction\n",
    "    unnorm_prediction = norm_prediction * values_range + min_value\n",
    "    \n",
    "    all_results = {'last_observed_city_level' : last_observed_city_level,\n",
    "               'the_prediction' : unnorm_prediction}\n",
    "    \n",
    "    return  all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we predict the river level in the city of Mainz 12 hours (48 timesteps) into the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_city = 'Mainz'\n",
    "future_timesteps = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"921.7777777777778\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# zoomed plot\n",
    "plot_timeseries('Mainz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 12s 30us/sample - loss: 0.0013 - val_loss: 7.6850e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 5.7048e-05 - val_loss: 4.1824e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 3.5537e-05 - val_loss: 3.2118e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 3.0241e-05 - val_loss: 3.0732e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 2.8631e-05 - val_loss: 2.7738e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.7547e-05 - val_loss: 2.7127e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.6602e-05 - val_loss: 2.6845e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 8s 18us/sample - loss: 2.6047e-05 - val_loss: 2.7311e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.5676e-05 - val_loss: 2.4365e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.5178e-05 - val_loss: 2.4041e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 2.4918e-05 - val_loss: 2.4045e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 2.4683e-05 - val_loss: 2.4949e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.4535e-05 - val_loss: 2.6802e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.4207e-05 - val_loss: 2.3532e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.4251e-05 - val_loss: 2.8629e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.4102e-05 - val_loss: 2.4501e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.3938e-05 - val_loss: 2.2840e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.3715e-05 - val_loss: 2.2792e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 2.3601e-05 - val_loss: 2.2966e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.3721e-05 - val_loss: 2.3353e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 0.0014 - val_loss: 7.5371e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 5.8267e-05 - val_loss: 4.4228e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 3.7612e-05 - val_loss: 3.3987e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 3.1662e-05 - val_loss: 3.0206e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.9547e-05 - val_loss: 2.9831e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.8354e-05 - val_loss: 2.8115e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 2.7257e-05 - val_loss: 2.6403e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 2.6309e-05 - val_loss: 2.6977e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.5815e-05 - val_loss: 2.9491e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.5519e-05 - val_loss: 2.7561e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.5027e-05 - val_loss: 2.7533e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 8s 18us/sample - loss: 2.5057e-05 - val_loss: 2.7687e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.4305e-05 - val_loss: 2.3595e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.4437e-05 - val_loss: 2.4091e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.4265e-05 - val_loss: 2.5977e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 8s 18us/sample - loss: 2.4212e-05 - val_loss: 2.3157e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.3973e-05 - val_loss: 2.6880e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.3914e-05 - val_loss: 2.5852e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.3819e-05 - val_loss: 2.5975e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.3786e-05 - val_loss: 2.3091e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 8.0776e-04 - val_loss: 6.7183e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 8s 18us/sample - loss: 5.1328e-05 - val_loss: 3.9501e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 8s 18us/sample - loss: 3.4837e-05 - val_loss: 3.1870e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 3.0871e-05 - val_loss: 3.0656e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.9127e-05 - val_loss: 2.7924e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.7635e-05 - val_loss: 2.6598e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.6898e-05 - val_loss: 2.5545e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.5966e-05 - val_loss: 2.4716e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.5645e-05 - val_loss: 2.6932e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.5125e-05 - val_loss: 2.8155e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.4695e-05 - val_loss: 2.3828e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 8s 18us/sample - loss: 2.4637e-05 - val_loss: 3.1829e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 8s 18us/sample - loss: 2.4437e-05 - val_loss: 2.3363e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.4186e-05 - val_loss: 2.6629e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.4187e-05 - val_loss: 2.4610e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.4272e-05 - val_loss: 2.3698e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.3992e-05 - val_loss: 2.5745e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.3942e-05 - val_loss: 2.3886e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.3792e-05 - val_loss: 2.5746e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.3766e-05 - val_loss: 2.3540e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 9.8071e-04 - val_loss: 7.3731e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 5.3356e-05 - val_loss: 3.8063e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 3.3623e-05 - val_loss: 3.1570e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 3.0442e-05 - val_loss: 2.9279e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.8815e-05 - val_loss: 2.7869e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.7559e-05 - val_loss: 2.8515e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.6383e-05 - val_loss: 2.5477e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.5693e-05 - val_loss: 2.7974e-05\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.5485e-05 - val_loss: 2.4094e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.4542e-05 - val_loss: 2.3799e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.4692e-05 - val_loss: 3.0384e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.4201e-05 - val_loss: 2.6494e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.4748e-05 - val_loss: 2.8236e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.4045e-05 - val_loss: 2.3393e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.4158e-05 - val_loss: 2.3220e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.3713e-05 - val_loss: 2.5283e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 8s 18us/sample - loss: 2.4150e-05 - val_loss: 2.2884e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.3602e-05 - val_loss: 2.2845e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.3743e-05 - val_loss: 2.2806e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.3741e-05 - val_loss: 2.3161e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 9.6115e-04 - val_loss: 6.8696e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 4.8344e-05 - val_loss: 3.4412e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 3.1536e-05 - val_loss: 2.9777e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.9236e-05 - val_loss: 2.9086e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.7812e-05 - val_loss: 2.7242e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.6876e-05 - val_loss: 2.6438e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.5926e-05 - val_loss: 2.5130e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.5385e-05 - val_loss: 2.6235e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.5497e-05 - val_loss: 2.8898e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.4881e-05 - val_loss: 2.4096e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.4445e-05 - val_loss: 2.3541e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.4541e-05 - val_loss: 2.3328e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.4350e-05 - val_loss: 2.4323e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.4078e-05 - val_loss: 2.6507e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.4048e-05 - val_loss: 2.3092e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.3922e-05 - val_loss: 2.5922e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 8s 18us/sample - loss: 2.4204e-05 - val_loss: 3.2880e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.4043e-05 - val_loss: 2.3111e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.3617e-05 - val_loss: 2.2863e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.3801e-05 - val_loss: 2.2814e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 10s 25us/sample - loss: 0.0011 - val_loss: 6.2952e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 4.4827e-05 - val_loss: 3.4177e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 3.0962e-05 - val_loss: 2.9518e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 8s 18us/sample - loss: 2.8696e-05 - val_loss: 2.8493e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.7595e-05 - val_loss: 2.6908e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 8s 18us/sample - loss: 2.6660e-05 - val_loss: 2.5893e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.5807e-05 - val_loss: 2.6716e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.5203e-05 - val_loss: 2.4451e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.5235e-05 - val_loss: 2.5794e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.4692e-05 - val_loss: 2.5273e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.4628e-05 - val_loss: 2.5364e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.4573e-05 - val_loss: 2.3628e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.4422e-05 - val_loss: 2.4444e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.3937e-05 - val_loss: 2.3355e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.4227e-05 - val_loss: 2.3296e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.3748e-05 - val_loss: 3.2353e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.3894e-05 - val_loss: 2.4059e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.3806e-05 - val_loss: 2.4494e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.3725e-05 - val_loss: 2.6390e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.3723e-05 - val_loss: 2.2995e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 6.4396e-04 - val_loss: 6.4169e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 4.8143e-05 - val_loss: 3.7508e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 3.4132e-05 - val_loss: 3.1906e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 3.1062e-05 - val_loss: 3.0027e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.9400e-05 - val_loss: 2.8477e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.7855e-05 - val_loss: 2.7459e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.6499e-05 - val_loss: 2.5418e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 8s 21us/sample - loss: 2.5762e-05 - val_loss: 2.5560e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.5424e-05 - val_loss: 2.4151e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.4893e-05 - val_loss: 2.5302e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.4484e-05 - val_loss: 2.3738e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.4599e-05 - val_loss: 2.9978e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.4374e-05 - val_loss: 2.3255e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.4017e-05 - val_loss: 2.3848e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 10s 25us/sample - loss: 2.4021e-05 - val_loss: 2.3055e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 11s 26us/sample - loss: 2.3798e-05 - val_loss: 2.3535e-05\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.3967e-05 - val_loss: 2.3003e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.4093e-05 - val_loss: 2.2953e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.3591e-05 - val_loss: 2.5549e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.3860e-05 - val_loss: 2.2858e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 9s 23us/sample - loss: 7.5277e-04 - val_loss: 6.2177e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 4.5867e-05 - val_loss: 3.5064e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 3.2215e-05 - val_loss: 3.0887e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.9675e-05 - val_loss: 2.8721e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.8420e-05 - val_loss: 2.7596e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.7439e-05 - val_loss: 2.6309e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.6750e-05 - val_loss: 2.8222e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.5669e-05 - val_loss: 2.4661e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.5462e-05 - val_loss: 2.4432e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.5143e-05 - val_loss: 2.3783e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.4532e-05 - val_loss: 2.4079e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.4570e-05 - val_loss: 2.4227e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.4244e-05 - val_loss: 2.3204e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.4068e-05 - val_loss: 3.0817e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.4311e-05 - val_loss: 2.3147e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 8s 18us/sample - loss: 2.3877e-05 - val_loss: 2.3163e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.3879e-05 - val_loss: 2.2887e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.3662e-05 - val_loss: 2.3697e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.3844e-05 - val_loss: 2.4389e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.3683e-05 - val_loss: 2.3011e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 0.0011 - val_loss: 7.0290e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 5.0240e-05 - val_loss: 3.6269e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 3.2916e-05 - val_loss: 3.0859e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 3.0081e-05 - val_loss: 2.9022e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.8519e-05 - val_loss: 2.8227e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.7176e-05 - val_loss: 2.8018e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.6396e-05 - val_loss: 2.6255e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.5764e-05 - val_loss: 2.4598e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.5192e-05 - val_loss: 2.4451e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.5171e-05 - val_loss: 2.4000e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.4712e-05 - val_loss: 2.3861e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.4318e-05 - val_loss: 2.4709e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.4192e-05 - val_loss: 2.3594e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.4092e-05 - val_loss: 2.3176e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.3901e-05 - val_loss: 2.3743e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.4009e-05 - val_loss: 2.4555e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.3760e-05 - val_loss: 2.3755e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.3866e-05 - val_loss: 2.2853e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.3536e-05 - val_loss: 2.4404e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.3715e-05 - val_loss: 2.4161e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 9s 23us/sample - loss: 4.7512e-04 - val_loss: 3.5174e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 3.1648e-05 - val_loss: 2.9645e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.9414e-05 - val_loss: 2.8629e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.7745e-05 - val_loss: 2.6448e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.6946e-05 - val_loss: 2.4763e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.7135e-05 - val_loss: 3.0611e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.6720e-05 - val_loss: 2.3509e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.7075e-05 - val_loss: 2.5185e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.5896e-05 - val_loss: 2.8733e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.6202e-05 - val_loss: 2.3181e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.5772e-05 - val_loss: 2.5999e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.5755e-05 - val_loss: 3.7585e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.5510e-05 - val_loss: 2.2902e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.5041e-05 - val_loss: 2.2756e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.5111e-05 - val_loss: 2.2765e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.5180e-05 - val_loss: 2.2612e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.4824e-05 - val_loss: 2.5794e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.4771e-05 - val_loss: 2.2537e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.4848e-05 - val_loss: 2.2635e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.4190e-05 - val_loss: 2.2507e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 7.0672e-04 - val_loss: 4.8134e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 3.5512e-05 - val_loss: 3.0334e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.9494e-05 - val_loss: 2.8129e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.7955e-05 - val_loss: 2.6819e-05\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.7061e-05 - val_loss: 2.5195e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.7194e-05 - val_loss: 2.9060e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.6976e-05 - val_loss: 2.6429e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.6904e-05 - val_loss: 2.4761e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.5807e-05 - val_loss: 2.3893e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.6317e-05 - val_loss: 2.3529e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.6234e-05 - val_loss: 2.8172e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.5551e-05 - val_loss: 2.4403e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 10s 24us/sample - loss: 2.5479e-05 - val_loss: 2.5204e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 10s 23us/sample - loss: 2.5107e-05 - val_loss: 2.4154e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.5094e-05 - val_loss: 2.7353e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.5534e-05 - val_loss: 2.4067e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.5334e-05 - val_loss: 2.2890e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.4671e-05 - val_loss: 2.9006e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.4743e-05 - val_loss: 2.4359e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.4942e-05 - val_loss: 2.4243e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 10s 25us/sample - loss: 9.7882e-04 - val_loss: 3.7235e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 3.2819e-05 - val_loss: 3.1207e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.9811e-05 - val_loss: 2.8965e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.7968e-05 - val_loss: 2.6713e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 8s 21us/sample - loss: 2.7353e-05 - val_loss: 2.9153e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.7225e-05 - val_loss: 2.4724e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.7382e-05 - val_loss: 2.7196e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.7310e-05 - val_loss: 2.6169e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.7401e-05 - val_loss: 2.4929e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.6701e-05 - val_loss: 2.4055e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 10s 23us/sample - loss: 2.6940e-05 - val_loss: 2.8170e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.7075e-05 - val_loss: 3.6744e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.6172e-05 - val_loss: 2.8038e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.6448e-05 - val_loss: 2.3244e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.6855e-05 - val_loss: 2.3915e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.6220e-05 - val_loss: 2.5415e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.6247e-05 - val_loss: 3.3015e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 9s 23us/sample - loss: 2.5990e-05 - val_loss: 2.4013e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 8s 21us/sample - loss: 2.5670e-05 - val_loss: 2.3231e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.6259e-05 - val_loss: 4.5781e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 10s 25us/sample - loss: 7.4469e-04 - val_loss: 4.5564e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 3.4951e-05 - val_loss: 3.1007e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.9524e-05 - val_loss: 2.9231e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.8044e-05 - val_loss: 2.6710e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.7013e-05 - val_loss: 2.7208e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.6435e-05 - val_loss: 2.4511e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.6504e-05 - val_loss: 2.9281e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.6714e-05 - val_loss: 2.9843e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.6010e-05 - val_loss: 2.3608e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.5568e-05 - val_loss: 2.4589e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.5883e-05 - val_loss: 2.3940e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.5431e-05 - val_loss: 2.4936e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.5069e-05 - val_loss: 2.4824e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.5001e-05 - val_loss: 2.4273e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.5560e-05 - val_loss: 2.5399e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.4400e-05 - val_loss: 2.4874e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.4540e-05 - val_loss: 2.4882e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.4638e-05 - val_loss: 2.2708e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.4245e-05 - val_loss: 2.4669e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.4257e-05 - val_loss: 2.2684e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 11s 28us/sample - loss: 5.6674e-04 - val_loss: 4.9240e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 11s 28us/sample - loss: 3.6103e-05 - val_loss: 3.0634e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 10s 24us/sample - loss: 2.8887e-05 - val_loss: 2.9308e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 10s 24us/sample - loss: 2.7256e-05 - val_loss: 2.8024e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.6848e-05 - val_loss: 2.7503e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 10s 23us/sample - loss: 2.6586e-05 - val_loss: 2.4235e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.6680e-05 - val_loss: 2.6228e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 9s 23us/sample - loss: 2.6161e-05 - val_loss: 2.3752e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.5699e-05 - val_loss: 2.5465e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.5732e-05 - val_loss: 2.9073e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.5312e-05 - val_loss: 2.3430e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 9s 23us/sample - loss: 2.5735e-05 - val_loss: 2.3363e-05\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.5424e-05 - val_loss: 2.3186e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.4662e-05 - val_loss: 2.3758e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.5944e-05 - val_loss: 2.9364e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.4830e-05 - val_loss: 2.4018e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.5002e-05 - val_loss: 2.3351e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.4622e-05 - val_loss: 2.6727e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.4817e-05 - val_loss: 2.3155e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.4560e-05 - val_loss: 2.2946e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 10s 23us/sample - loss: 0.0185 - val_loss: 8.9230e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 5.4456e-05 - val_loss: 4.2549e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 3.8459e-05 - val_loss: 3.5307e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 3.3455e-05 - val_loss: 3.1948e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 3.1020e-05 - val_loss: 2.9993e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.9514e-05 - val_loss: 2.9404e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 8s 21us/sample - loss: 2.8229e-05 - val_loss: 2.8196e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.7139e-05 - val_loss: 2.6429e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.6567e-05 - val_loss: 2.6335e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.6755e-05 - val_loss: 2.6337e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.6834e-05 - val_loss: 2.5929e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.6065e-05 - val_loss: 2.5121e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.6816e-05 - val_loss: 2.4571e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.6051e-05 - val_loss: 2.4421e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.6124e-05 - val_loss: 2.7429e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.6026e-05 - val_loss: 2.3610e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.5708e-05 - val_loss: 2.6324e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.5542e-05 - val_loss: 2.3617e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.5783e-05 - val_loss: 3.2287e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.5370e-05 - val_loss: 2.9157e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 9s 23us/sample - loss: 7.4626e-04 - val_loss: 4.9243e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 3.5968e-05 - val_loss: 3.0594e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.9492e-05 - val_loss: 2.8633e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.7648e-05 - val_loss: 3.0245e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.6391e-05 - val_loss: 2.6183e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.5876e-05 - val_loss: 2.4728e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.5400e-05 - val_loss: 2.6510e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.5572e-05 - val_loss: 2.3558e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.5681e-05 - val_loss: 3.0176e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.5710e-05 - val_loss: 2.3433e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.5203e-05 - val_loss: 2.5426e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.4705e-05 - val_loss: 2.3530e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 8s 21us/sample - loss: 2.4752e-05 - val_loss: 2.3121e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.4731e-05 - val_loss: 2.3870e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.4503e-05 - val_loss: 2.4054e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.4489e-05 - val_loss: 2.4009e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.4150e-05 - val_loss: 2.4012e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.4223e-05 - val_loss: 3.1827e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 8s 21us/sample - loss: 2.4406e-05 - val_loss: 2.2792e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.4250e-05 - val_loss: 2.2538e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 8.4979e-04 - val_loss: 4.8240e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 3.5345e-05 - val_loss: 3.1071e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 3.0134e-05 - val_loss: 2.8775e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.8323e-05 - val_loss: 2.7260e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 8s 21us/sample - loss: 2.6809e-05 - val_loss: 2.5707e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.5804e-05 - val_loss: 2.6954e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.5981e-05 - val_loss: 2.9035e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.5582e-05 - val_loss: 2.3604e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.5715e-05 - val_loss: 2.6274e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.5176e-05 - val_loss: 2.5632e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.4819e-05 - val_loss: 2.3158e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.5007e-05 - val_loss: 2.7546e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 8s 21us/sample - loss: 2.4495e-05 - val_loss: 2.3453e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.4537e-05 - val_loss: 2.4967e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.4578e-05 - val_loss: 2.3981e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.4293e-05 - val_loss: 2.3395e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.4468e-05 - val_loss: 2.3763e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.3974e-05 - val_loss: 2.4460e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.4200e-05 - val_loss: 2.2755e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.4029e-05 - val_loss: 2.5500e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410270/410270 [==============================] - 9s 23us/sample - loss: 2.3873e-04 - val_loss: 3.3804e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 3.1229e-05 - val_loss: 2.9391e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.9122e-05 - val_loss: 2.7035e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 8s 21us/sample - loss: 2.7496e-05 - val_loss: 3.0662e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.6285e-05 - val_loss: 2.5090e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.6076e-05 - val_loss: 2.6524e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.5811e-05 - val_loss: 2.4655e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.5098e-05 - val_loss: 2.4510e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 8s 21us/sample - loss: 2.4990e-05 - val_loss: 2.5787e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 10s 24us/sample - loss: 2.4788e-05 - val_loss: 2.4052e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.4574e-05 - val_loss: 2.3985e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.4466e-05 - val_loss: 2.4660e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.4442e-05 - val_loss: 2.6800e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.4280e-05 - val_loss: 2.4180e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.4198e-05 - val_loss: 2.3099e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.4212e-05 - val_loss: 2.4663e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.3966e-05 - val_loss: 2.3026e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.3947e-05 - val_loss: 2.3406e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.3908e-05 - val_loss: 2.2625e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.3319e-05 - val_loss: 2.2857e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 10s 23us/sample - loss: 6.6613e-04 - val_loss: 3.5265e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 3.1683e-05 - val_loss: 2.9158e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.9128e-05 - val_loss: 2.7167e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.8260e-05 - val_loss: 2.8499e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.9182e-05 - val_loss: 4.8009e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 9s 23us/sample - loss: 2.9562e-05 - val_loss: 3.4281e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 9s 23us/sample - loss: 2.7882e-05 - val_loss: 4.8197e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.9026e-05 - val_loss: 2.9779e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.8103e-05 - val_loss: 2.3581e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 8s 21us/sample - loss: 2.7675e-05 - val_loss: 2.5034e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.7521e-05 - val_loss: 2.3459e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 8s 21us/sample - loss: 2.7217e-05 - val_loss: 3.4818e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.7339e-05 - val_loss: 4.0036e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.6309e-05 - val_loss: 4.0839e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.6716e-05 - val_loss: 2.3600e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 8s 21us/sample - loss: 2.5328e-05 - val_loss: 2.3184e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.6252e-05 - val_loss: 3.3824e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.5386e-05 - val_loss: 3.9369e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 10s 24us/sample - loss: 2.5615e-05 - val_loss: 2.2447e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.5533e-05 - val_loss: 2.2848e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 11s 26us/sample - loss: 5.0607e-04 - val_loss: 3.4875e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 9s 23us/sample - loss: 3.1726e-05 - val_loss: 2.9662e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 10s 23us/sample - loss: 2.8604e-05 - val_loss: 2.7263e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 9s 23us/sample - loss: 2.7583e-05 - val_loss: 2.6250e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.7954e-05 - val_loss: 2.7952e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.8813e-05 - val_loss: 2.8625e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 10s 24us/sample - loss: 2.7303e-05 - val_loss: 4.2152e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.7428e-05 - val_loss: 2.3620e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.6980e-05 - val_loss: 3.6269e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.6904e-05 - val_loss: 4.8433e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.5919e-05 - val_loss: 2.4972e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.6793e-05 - val_loss: 2.3105e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 9s 23us/sample - loss: 2.5485e-05 - val_loss: 2.6589e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.5674e-05 - val_loss: 2.3189e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 10s 23us/sample - loss: 2.5666e-05 - val_loss: 2.5191e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.5494e-05 - val_loss: 2.4895e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 9s 23us/sample - loss: 2.5957e-05 - val_loss: 2.4681e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.5326e-05 - val_loss: 2.2869e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.5101e-05 - val_loss: 2.3151e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 9s 23us/sample - loss: 2.5333e-05 - val_loss: 2.2605e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 10s 24us/sample - loss: 0.0020 - val_loss: 5.2525e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 8s 21us/sample - loss: 4.0371e-05 - val_loss: 3.6189e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 8s 21us/sample - loss: 3.3595e-05 - val_loss: 3.2806e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 3.1287e-05 - val_loss: 3.2374e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 9s 23us/sample - loss: 3.1109e-05 - val_loss: 2.7979e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 11s 26us/sample - loss: 3.2151e-05 - val_loss: 3.7619e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 3.5814e-05 - val_loss: 3.6834e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 10s 23us/sample - loss: 3.6360e-05 - val_loss: 2.7505e-05\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410270/410270 [==============================] - 9s 21us/sample - loss: 3.3392e-05 - val_loss: 2.6833e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 3.6355e-05 - val_loss: 2.6367e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 3.3179e-05 - val_loss: 3.8082e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 3.4741e-05 - val_loss: 2.7271e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 3.3245e-05 - val_loss: 5.7043e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 10s 25us/sample - loss: 3.3380e-05 - val_loss: 2.6203e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 10s 23us/sample - loss: 3.2812e-05 - val_loss: 2.4957e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 3.2883e-05 - val_loss: 3.2517e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 3.2571e-05 - val_loss: 2.9152e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 3.2457e-05 - val_loss: 5.0462e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 3.1955e-05 - val_loss: 4.5376e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 9s 23us/sample - loss: 3.1667e-05 - val_loss: 3.2462e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 11s 26us/sample - loss: 7.3148e-04 - val_loss: 5.1679e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 3.5919e-05 - val_loss: 3.1319e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 3.0128e-05 - val_loss: 3.0866e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.8510e-05 - val_loss: 2.6916e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.7915e-05 - val_loss: 2.5939e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.7722e-05 - val_loss: 3.4648e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.6919e-05 - val_loss: 2.5319e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.6913e-05 - val_loss: 2.5009e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.7059e-05 - val_loss: 2.5314e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.6330e-05 - val_loss: 3.9465e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.6060e-05 - val_loss: 4.5220e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.5962e-05 - val_loss: 2.7410e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.5776e-05 - val_loss: 2.8341e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 10s 24us/sample - loss: 2.5764e-05 - val_loss: 2.3295e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.6054e-05 - val_loss: 2.4635e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.5066e-05 - val_loss: 2.7659e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 10s 25us/sample - loss: 2.5564e-05 - val_loss: 2.4604e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.5178e-05 - val_loss: 2.3493e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.5041e-05 - val_loss: 2.3125e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.4541e-05 - val_loss: 2.3198e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 10s 24us/sample - loss: 6.3841e-04 - val_loss: 4.5127e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 10s 23us/sample - loss: 3.4062e-05 - val_loss: 3.0823e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 10s 24us/sample - loss: 2.9644e-05 - val_loss: 2.7833e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.7817e-05 - val_loss: 2.7152e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.7641e-05 - val_loss: 2.5174e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.8135e-05 - val_loss: 3.3848e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.7478e-05 - val_loss: 2.5154e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.7417e-05 - val_loss: 2.4393e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 9s 23us/sample - loss: 2.7407e-05 - val_loss: 2.6202e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.6597e-05 - val_loss: 2.6841e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 10s 24us/sample - loss: 2.6453e-05 - val_loss: 2.3702e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.5992e-05 - val_loss: 2.4160e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 8s 21us/sample - loss: 2.6109e-05 - val_loss: 2.4297e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.5669e-05 - val_loss: 2.3281e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.5950e-05 - val_loss: 2.5021e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.5494e-05 - val_loss: 2.7757e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.5513e-05 - val_loss: 2.6767e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 9s 23us/sample - loss: 2.4878e-05 - val_loss: 2.6413e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 9s 23us/sample - loss: 2.5302e-05 - val_loss: 2.2756e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 10s 24us/sample - loss: 2.5046e-05 - val_loss: 2.8642e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 10s 24us/sample - loss: 5.9105e-04 - val_loss: 4.3791e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 3.9644e-05 - val_loss: 3.9728e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 3.5608e-05 - val_loss: 5.0051e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 3.2278e-05 - val_loss: 2.9165e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 3.2128e-05 - val_loss: 2.7905e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 3.0641e-05 - val_loss: 3.0166e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.9896e-05 - val_loss: 3.1652e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 3.0106e-05 - val_loss: 2.7484e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.9137e-05 - val_loss: 2.6913e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.8548e-05 - val_loss: 2.7886e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.8903e-05 - val_loss: 3.4598e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.8170e-05 - val_loss: 5.5369e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.7637e-05 - val_loss: 2.4516e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.7862e-05 - val_loss: 2.6371e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.7167e-05 - val_loss: 2.4382e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.7447e-05 - val_loss: 2.6844e-05\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.7566e-05 - val_loss: 2.9144e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.7283e-05 - val_loss: 2.6727e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 8s 21us/sample - loss: 2.7070e-05 - val_loss: 2.6376e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.7137e-05 - val_loss: 3.6635e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 9s 23us/sample - loss: 7.5721e-04 - val_loss: 4.0193e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 3.2768e-05 - val_loss: 2.9371e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.8870e-05 - val_loss: 2.9240e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.7632e-05 - val_loss: 2.6682e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.6791e-05 - val_loss: 2.5265e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.6433e-05 - val_loss: 2.5515e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.6599e-05 - val_loss: 2.8880e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.7123e-05 - val_loss: 2.5078e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.6456e-05 - val_loss: 2.3656e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 8s 21us/sample - loss: 2.6331e-05 - val_loss: 2.4246e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 8s 21us/sample - loss: 2.6663e-05 - val_loss: 2.6371e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.5690e-05 - val_loss: 2.3462e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.5379e-05 - val_loss: 2.6683e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.5758e-05 - val_loss: 4.8307e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.5592e-05 - val_loss: 2.9584e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.5660e-05 - val_loss: 2.5176e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.5171e-05 - val_loss: 2.3100e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.5605e-05 - val_loss: 2.3157e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.5016e-05 - val_loss: 2.3155e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.5479e-05 - val_loss: 2.8679e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 12s 28us/sample - loss: 9.8766e-04 - val_loss: 6.3835e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 9s 23us/sample - loss: 4.1377e-05 - val_loss: 3.1991e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 3.0337e-05 - val_loss: 2.8741e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.8818e-05 - val_loss: 2.7126e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 9s 23us/sample - loss: 2.7565e-05 - val_loss: 2.6458e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.7335e-05 - val_loss: 2.5731e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.6402e-05 - val_loss: 2.4204e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 9s 23us/sample - loss: 2.6740e-05 - val_loss: 2.4091e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 9s 23us/sample - loss: 2.6491e-05 - val_loss: 5.3501e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.6029e-05 - val_loss: 2.9044e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.6186e-05 - val_loss: 2.7190e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.5967e-05 - val_loss: 2.6748e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.5343e-05 - val_loss: 2.5396e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.5617e-05 - val_loss: 3.9542e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 9s 23us/sample - loss: 2.5214e-05 - val_loss: 2.3411e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 10s 23us/sample - loss: 2.5193e-05 - val_loss: 2.5346e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 9s 23us/sample - loss: 2.4980e-05 - val_loss: 2.4936e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 10s 24us/sample - loss: 2.5001e-05 - val_loss: 2.3099e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 9s 23us/sample - loss: 2.4633e-05 - val_loss: 2.6047e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.5024e-05 - val_loss: 2.3309e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 10s 25us/sample - loss: 0.0085 - val_loss: 1.3564e-04\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 9.5344e-05 - val_loss: 7.5930e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 10s 24us/sample - loss: 6.6846e-05 - val_loss: 5.9867e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 5.1579e-05 - val_loss: 4.4444e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 3.8046e-05 - val_loss: 3.3733e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 9s 23us/sample - loss: 3.1890e-05 - val_loss: 3.0443e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.9493e-05 - val_loss: 2.8682e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 8s 21us/sample - loss: 2.8162e-05 - val_loss: 2.9931e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 9s 23us/sample - loss: 2.7279e-05 - val_loss: 2.7924e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 9s 23us/sample - loss: 2.6743e-05 - val_loss: 3.0186e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.6219e-05 - val_loss: 2.4927e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.6154e-05 - val_loss: 2.4981e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 10s 25us/sample - loss: 2.5565e-05 - val_loss: 2.4764e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.5727e-05 - val_loss: 2.6097e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.5108e-05 - val_loss: 2.3732e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.5033e-05 - val_loss: 3.0587e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 9s 23us/sample - loss: 2.4725e-05 - val_loss: 2.5703e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 10s 25us/sample - loss: 2.4663e-05 - val_loss: 2.3644e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.4750e-05 - val_loss: 2.3161e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.4576e-05 - val_loss: 2.3937e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 5s 12us/sample - loss: 0.0018 - val_loss: 1.0134e-04\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 4s 9us/sample - loss: 7.7411e-05 - val_loss: 5.7482e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 4s 9us/sample - loss: 4.6521e-05 - val_loss: 3.9068e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 4s 9us/sample - loss: 3.6059e-05 - val_loss: 3.4146e-05\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410270/410270 [==============================] - 4s 9us/sample - loss: 3.3000e-05 - val_loss: 3.1866e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 4s 9us/sample - loss: 3.1122e-05 - val_loss: 3.0968e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 4s 9us/sample - loss: 2.9116e-05 - val_loss: 2.8236e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 4s 10us/sample - loss: 2.7813e-05 - val_loss: 2.8207e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 4s 9us/sample - loss: 2.6612e-05 - val_loss: 2.6462e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 4s 10us/sample - loss: 2.5726e-05 - val_loss: 2.9602e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 5s 11us/sample - loss: 2.5465e-05 - val_loss: 2.7705e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 4s 9us/sample - loss: 2.4583e-05 - val_loss: 2.4976e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 4s 9us/sample - loss: 2.4642e-05 - val_loss: 2.6788e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 4s 10us/sample - loss: 2.4380e-05 - val_loss: 2.6838e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 4s 10us/sample - loss: 2.4037e-05 - val_loss: 2.4096e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 4s 9us/sample - loss: 2.4098e-05 - val_loss: 2.3347e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 4s 9us/sample - loss: 2.3872e-05 - val_loss: 2.5474e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 4s 9us/sample - loss: 2.3904e-05 - val_loss: 2.4085e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 4s 9us/sample - loss: 2.3649e-05 - val_loss: 2.3276e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 4s 10us/sample - loss: 2.3566e-05 - val_loss: 2.4375e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 0.0013 - val_loss: 8.3646e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 4s 10us/sample - loss: 6.4357e-05 - val_loss: 4.8642e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 4s 9us/sample - loss: 4.0720e-05 - val_loss: 3.5975e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 4s 9us/sample - loss: 3.4204e-05 - val_loss: 3.3160e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 4s 10us/sample - loss: 3.2036e-05 - val_loss: 3.1145e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 4s 10us/sample - loss: 3.0394e-05 - val_loss: 2.9348e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 4s 10us/sample - loss: 2.8933e-05 - val_loss: 2.7727e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 4s 9us/sample - loss: 2.7171e-05 - val_loss: 2.6249e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 4s 9us/sample - loss: 2.6165e-05 - val_loss: 2.8068e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 4s 9us/sample - loss: 2.5267e-05 - val_loss: 2.7010e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 4s 9us/sample - loss: 2.5105e-05 - val_loss: 2.4164e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 4s 9us/sample - loss: 2.4298e-05 - val_loss: 2.3666e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 4s 9us/sample - loss: 2.4302e-05 - val_loss: 2.3396e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 4s 9us/sample - loss: 2.4375e-05 - val_loss: 2.4445e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 4s 9us/sample - loss: 2.3951e-05 - val_loss: 2.4163e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 4s 9us/sample - loss: 2.3905e-05 - val_loss: 2.3002e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 4s 9us/sample - loss: 2.3729e-05 - val_loss: 2.9357e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 4s 9us/sample - loss: 2.3616e-05 - val_loss: 2.2864e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 4s 9us/sample - loss: 2.3621e-05 - val_loss: 2.3862e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 4s 9us/sample - loss: 2.3522e-05 - val_loss: 2.2969e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 5s 12us/sample - loss: 0.0012 - val_loss: 7.7136e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 4s 9us/sample - loss: 5.8148e-05 - val_loss: 4.2481e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 4s 9us/sample - loss: 3.5332e-05 - val_loss: 3.1529e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 4s 9us/sample - loss: 3.0428e-05 - val_loss: 2.9605e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 4s 9us/sample - loss: 2.8649e-05 - val_loss: 2.7727e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 4s 9us/sample - loss: 2.7262e-05 - val_loss: 2.6502e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 4s 9us/sample - loss: 2.6077e-05 - val_loss: 2.5620e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 4s 9us/sample - loss: 2.5217e-05 - val_loss: 2.4903e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 4s 9us/sample - loss: 2.4732e-05 - val_loss: 2.6949e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 4s 9us/sample - loss: 2.4660e-05 - val_loss: 2.7584e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 4s 9us/sample - loss: 2.4004e-05 - val_loss: 2.3502e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 4s 9us/sample - loss: 2.3961e-05 - val_loss: 2.3075e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 4s 9us/sample - loss: 2.3620e-05 - val_loss: 2.3517e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 4s 9us/sample - loss: 2.3662e-05 - val_loss: 2.4636e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 4s 9us/sample - loss: 2.3525e-05 - val_loss: 2.4917e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 4s 9us/sample - loss: 2.3387e-05 - val_loss: 2.2648e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 4s 9us/sample - loss: 2.3424e-05 - val_loss: 2.3404e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 4s 9us/sample - loss: 2.3227e-05 - val_loss: 2.2752e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 4s 10us/sample - loss: 2.3197e-05 - val_loss: 2.2839e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 4s 11us/sample - loss: 2.3116e-05 - val_loss: 2.5849e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 0.0010 - val_loss: 7.7432e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 5.9793e-05 - val_loss: 4.5357e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 6s 16us/sample - loss: 3.8060e-05 - val_loss: 3.3311e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 3.1453e-05 - val_loss: 2.9972e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.9390e-05 - val_loss: 3.0006e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.8141e-05 - val_loss: 2.7870e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.7091e-05 - val_loss: 2.9568e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.6200e-05 - val_loss: 2.5291e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 5s 12us/sample - loss: 2.5592e-05 - val_loss: 2.4537e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 5s 12us/sample - loss: 2.5077e-05 - val_loss: 2.9649e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 5s 12us/sample - loss: 2.4592e-05 - val_loss: 2.5165e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.4305e-05 - val_loss: 2.5638e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.4233e-05 - val_loss: 2.4623e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 5s 12us/sample - loss: 2.4061e-05 - val_loss: 2.4091e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 5s 12us/sample - loss: 2.3947e-05 - val_loss: 2.3113e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 5s 12us/sample - loss: 2.3959e-05 - val_loss: 2.3010e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 5s 12us/sample - loss: 2.3810e-05 - val_loss: 2.3390e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.3531e-05 - val_loss: 2.5899e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.3536e-05 - val_loss: 2.2872e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.3693e-05 - val_loss: 2.2959e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 0.0011 - val_loss: 7.9081e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 5.9640e-05 - val_loss: 4.4528e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 3.8196e-05 - val_loss: 3.4551e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 3.3414e-05 - val_loss: 3.3425e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 3.1718e-05 - val_loss: 3.0730e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 6s 13us/sample - loss: 3.0128e-05 - val_loss: 2.9299e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.8481e-05 - val_loss: 2.7668e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.6944e-05 - val_loss: 4.6213e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.5963e-05 - val_loss: 2.4814e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.5109e-05 - val_loss: 2.4290e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 6s 13us/sample - loss: 2.4726e-05 - val_loss: 2.6290e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.4395e-05 - val_loss: 2.3990e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.4090e-05 - val_loss: 2.4548e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.3888e-05 - val_loss: 2.4326e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.3844e-05 - val_loss: 2.3077e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 6s 13us/sample - loss: 2.3723e-05 - val_loss: 2.4086e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.3699e-05 - val_loss: 2.3507e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.3634e-05 - val_loss: 2.7632e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.3420e-05 - val_loss: 2.2945e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.3383e-05 - val_loss: 2.4104e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 8.6109e-04 - val_loss: 7.2087e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 5s 12us/sample - loss: 5.5976e-05 - val_loss: 4.3070e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 3.7309e-05 - val_loss: 3.3541e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 3.1889e-05 - val_loss: 3.0412e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.9563e-05 - val_loss: 2.8528e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.7970e-05 - val_loss: 2.7005e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.6591e-05 - val_loss: 2.6239e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.5684e-05 - val_loss: 2.4693e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.4968e-05 - val_loss: 2.5788e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.4368e-05 - val_loss: 2.3841e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.4086e-05 - val_loss: 2.3366e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.3956e-05 - val_loss: 2.5135e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.4052e-05 - val_loss: 3.0468e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.3671e-05 - val_loss: 2.4742e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 5s 12us/sample - loss: 2.3523e-05 - val_loss: 2.3464e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 5s 12us/sample - loss: 2.3474e-05 - val_loss: 2.2913e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.3330e-05 - val_loss: 2.2863e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.3375e-05 - val_loss: 2.2864e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 5s 12us/sample - loss: 2.3308e-05 - val_loss: 2.2854e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 5s 12us/sample - loss: 2.3301e-05 - val_loss: 2.3660e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 0.0015 - val_loss: 7.9462e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 5.7798e-05 - val_loss: 4.1633e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 3.5155e-05 - val_loss: 3.1849e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 3.0245e-05 - val_loss: 2.9274e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.8497e-05 - val_loss: 2.9789e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 5s 12us/sample - loss: 2.7337e-05 - val_loss: 2.6569e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.6351e-05 - val_loss: 2.5639e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.5545e-05 - val_loss: 2.4910e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 5s 12us/sample - loss: 2.5141e-05 - val_loss: 2.4560e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 5s 12us/sample - loss: 2.4676e-05 - val_loss: 2.6775e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 5s 12us/sample - loss: 2.4453e-05 - val_loss: 2.3744e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.4199e-05 - val_loss: 2.3739e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 5s 12us/sample - loss: 2.4030e-05 - val_loss: 2.3425e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.4060e-05 - val_loss: 2.3253e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 5s 12us/sample - loss: 2.3788e-05 - val_loss: 2.3265e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 5s 12us/sample - loss: 2.3651e-05 - val_loss: 2.3208e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.3620e-05 - val_loss: 2.3196e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 5s 12us/sample - loss: 2.3852e-05 - val_loss: 3.0022e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 5s 12us/sample - loss: 2.3365e-05 - val_loss: 2.2993e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 5s 12us/sample - loss: 2.3551e-05 - val_loss: 2.2921e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 0.0016 - val_loss: 8.4483e-05\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410270/410270 [==============================] - 5s 12us/sample - loss: 6.5173e-05 - val_loss: 4.8800e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 5s 12us/sample - loss: 4.0037e-05 - val_loss: 3.5194e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 5s 12us/sample - loss: 3.3193e-05 - val_loss: 3.1725e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 5s 12us/sample - loss: 3.0558e-05 - val_loss: 2.9633e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.8796e-05 - val_loss: 2.7822e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 5s 12us/sample - loss: 2.7452e-05 - val_loss: 2.7159e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 5s 12us/sample - loss: 2.6280e-05 - val_loss: 2.7667e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.5381e-05 - val_loss: 2.5048e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 5s 12us/sample - loss: 2.4903e-05 - val_loss: 2.3892e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 5s 12us/sample - loss: 2.4473e-05 - val_loss: 2.4165e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 5s 12us/sample - loss: 2.4071e-05 - val_loss: 2.3455e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.3973e-05 - val_loss: 2.3011e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.3856e-05 - val_loss: 2.2907e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 5s 12us/sample - loss: 2.3625e-05 - val_loss: 2.5375e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 5s 12us/sample - loss: 2.3350e-05 - val_loss: 2.3656e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.3304e-05 - val_loss: 2.3087e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.3407e-05 - val_loss: 2.3464e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.2915e-05 - val_loss: 2.2347e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.2917e-05 - val_loss: 2.3105e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 0.0019 - val_loss: 9.3541e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 7.2173e-05 - val_loss: 5.4031e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 4.3543e-05 - val_loss: 3.7366e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 5s 12us/sample - loss: 3.4048e-05 - val_loss: 3.2331e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 3.1199e-05 - val_loss: 3.0554e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.9604e-05 - val_loss: 2.9771e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.8120e-05 - val_loss: 2.7356e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 5s 12us/sample - loss: 2.6947e-05 - val_loss: 2.5967e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 5s 12us/sample - loss: 2.6005e-05 - val_loss: 2.5174e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 5s 12us/sample - loss: 2.5383e-05 - val_loss: 2.4457e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.5004e-05 - val_loss: 2.7409e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 5s 12us/sample - loss: 2.4588e-05 - val_loss: 2.4379e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.4235e-05 - val_loss: 2.3521e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.4097e-05 - val_loss: 2.3646e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.4031e-05 - val_loss: 3.3387e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.3875e-05 - val_loss: 2.5360e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.3766e-05 - val_loss: 2.7583e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.3582e-05 - val_loss: 2.3701e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.3616e-05 - val_loss: 2.4099e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.3388e-05 - val_loss: 2.2838e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 4.6735e-04 - val_loss: 4.3634e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 6s 16us/sample - loss: 3.3681e-05 - val_loss: 2.9316e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 6s 16us/sample - loss: 2.8044e-05 - val_loss: 2.8456e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 2.6912e-05 - val_loss: 2.5457e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.6096e-05 - val_loss: 2.5035e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 11s 26us/sample - loss: 2.5974e-05 - val_loss: 2.8554e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 9s 23us/sample - loss: 2.6127e-05 - val_loss: 2.3507e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 8s 21us/sample - loss: 2.6516e-05 - val_loss: 2.3301e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.5386e-05 - val_loss: 3.0901e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 2.5746e-05 - val_loss: 2.3214e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.5182e-05 - val_loss: 2.3028e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 2.5064e-05 - val_loss: 4.3460e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 2.5205e-05 - val_loss: 2.2920e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 2.4695e-05 - val_loss: 2.3500e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.5028e-05 - val_loss: 3.1605e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.4729e-05 - val_loss: 2.4279e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 2.4661e-05 - val_loss: 2.2915e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.4859e-05 - val_loss: 2.4953e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 2.4544e-05 - val_loss: 2.2984e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.4378e-05 - val_loss: 2.3928e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 9.3658e-04 - val_loss: 6.4956e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 4.6651e-05 - val_loss: 3.4894e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 3.1626e-05 - val_loss: 2.9882e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 2.8627e-05 - val_loss: 2.7144e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.7553e-05 - val_loss: 2.5760e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 2.6616e-05 - val_loss: 2.4928e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 2.6830e-05 - val_loss: 2.4358e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.6362e-05 - val_loss: 2.4984e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.6311e-05 - val_loss: 2.7062e-05\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.6129e-05 - val_loss: 2.4003e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.6373e-05 - val_loss: 2.3615e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.5698e-05 - val_loss: 2.6869e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 2.5638e-05 - val_loss: 2.8613e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 2.5547e-05 - val_loss: 2.5290e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.5246e-05 - val_loss: 2.3969e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.5279e-05 - val_loss: 3.0694e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.5239e-05 - val_loss: 2.3278e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.5078e-05 - val_loss: 2.4077e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 2.4715e-05 - val_loss: 2.8219e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 2.4884e-05 - val_loss: 2.3074e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 6.6715e-04 - val_loss: 4.1997e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 3.4696e-05 - val_loss: 3.1308e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 3.0284e-05 - val_loss: 2.8989e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.8494e-05 - val_loss: 2.9280e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.7837e-05 - val_loss: 2.7926e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.7536e-05 - val_loss: 3.2645e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.7948e-05 - val_loss: 2.6039e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.7157e-05 - val_loss: 2.4510e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 6s 16us/sample - loss: 2.6297e-05 - val_loss: 2.5282e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 6s 16us/sample - loss: 2.7065e-05 - val_loss: 2.5909e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.6446e-05 - val_loss: 2.6627e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.7009e-05 - val_loss: 3.2473e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.5954e-05 - val_loss: 2.6756e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.5972e-05 - val_loss: 2.8706e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 6s 16us/sample - loss: 2.6187e-05 - val_loss: 2.7835e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.5771e-05 - val_loss: 2.5892e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.6021e-05 - val_loss: 2.5691e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.6237e-05 - val_loss: 2.3146e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.6006e-05 - val_loss: 2.5866e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 2.5395e-05 - val_loss: 2.4605e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 4.4006e-04 - val_loss: 5.1453e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 3.9425e-05 - val_loss: 3.2743e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 3.1498e-05 - val_loss: 2.9864e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 6s 13us/sample - loss: 2.9200e-05 - val_loss: 2.8303e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.8028e-05 - val_loss: 2.7825e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 6s 13us/sample - loss: 2.6796e-05 - val_loss: 2.5011e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.5902e-05 - val_loss: 2.5145e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.5415e-05 - val_loss: 3.4794e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.5339e-05 - val_loss: 2.3612e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 6s 13us/sample - loss: 2.4995e-05 - val_loss: 2.3838e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.5188e-05 - val_loss: 2.6080e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.4805e-05 - val_loss: 2.3375e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 6s 13us/sample - loss: 2.4699e-05 - val_loss: 4.2881e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.4632e-05 - val_loss: 2.5272e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.4450e-05 - val_loss: 2.3134e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.4527e-05 - val_loss: 2.4853e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 2.4249e-05 - val_loss: 3.0479e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.4114e-05 - val_loss: 2.7602e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.4366e-05 - val_loss: 2.3400e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.3865e-05 - val_loss: 2.6539e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 7.5862e-04 - val_loss: 6.2728e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 4.5679e-05 - val_loss: 3.6362e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 3.4324e-05 - val_loss: 3.2563e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 3.1186e-05 - val_loss: 2.9372e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.8974e-05 - val_loss: 2.7488e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.7262e-05 - val_loss: 2.6033e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 2.6497e-05 - val_loss: 2.6447e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.6233e-05 - val_loss: 3.0291e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 6s 13us/sample - loss: 2.5714e-05 - val_loss: 3.0357e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.5343e-05 - val_loss: 2.3681e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.5543e-05 - val_loss: 2.3450e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.5253e-05 - val_loss: 3.0911e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 2.4866e-05 - val_loss: 2.4588e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.4616e-05 - val_loss: 2.3618e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.4491e-05 - val_loss: 2.3854e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.4479e-05 - val_loss: 2.4245e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 2.4397e-05 - val_loss: 2.2907e-05\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.3959e-05 - val_loss: 2.2490e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.3918e-05 - val_loss: 2.3446e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.3807e-05 - val_loss: 2.7789e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 0.0154 - val_loss: 1.4345e-04\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 9.2043e-05 - val_loss: 6.4651e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 5.3618e-05 - val_loss: 4.4634e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 3.9708e-05 - val_loss: 3.6392e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 3.4695e-05 - val_loss: 3.3272e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 3.2435e-05 - val_loss: 3.1535e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 6s 16us/sample - loss: 3.1077e-05 - val_loss: 3.0230e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.9788e-05 - val_loss: 2.8781e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.8772e-05 - val_loss: 2.7836e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.7718e-05 - val_loss: 2.7068e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 2.7258e-05 - val_loss: 2.6363e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 2.6745e-05 - val_loss: 2.5177e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 2.6270e-05 - val_loss: 2.7103e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.5843e-05 - val_loss: 2.5597e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 2.5799e-05 - val_loss: 3.3045e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 2.5536e-05 - val_loss: 2.3768e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.5320e-05 - val_loss: 2.4865e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 2.5579e-05 - val_loss: 2.5392e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 2.5159e-05 - val_loss: 2.3440e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.4715e-05 - val_loss: 2.5409e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 8.4936e-04 - val_loss: 6.8498e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 4.9155e-05 - val_loss: 3.7491e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 3.3240e-05 - val_loss: 3.0877e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 6s 16us/sample - loss: 3.0003e-05 - val_loss: 3.1603e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 2.8644e-05 - val_loss: 2.7299e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.7077e-05 - val_loss: 2.7724e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.6578e-05 - val_loss: 2.4921e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.5749e-05 - val_loss: 2.5175e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.5184e-05 - val_loss: 2.3889e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.5303e-05 - val_loss: 2.7403e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 2.4767e-05 - val_loss: 2.4733e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.4606e-05 - val_loss: 3.0758e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.4633e-05 - val_loss: 2.3204e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 6s 16us/sample - loss: 2.4267e-05 - val_loss: 2.3166e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.4220e-05 - val_loss: 2.9216e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.4261e-05 - val_loss: 2.9868e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.4346e-05 - val_loss: 2.2903e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.4134e-05 - val_loss: 2.3541e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.3848e-05 - val_loss: 2.8244e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.4187e-05 - val_loss: 2.2907e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 7.6224e-04 - val_loss: 4.7107e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 6s 16us/sample - loss: 3.6011e-05 - val_loss: 3.3005e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 3.0514e-05 - val_loss: 3.0014e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 2.7974e-05 - val_loss: 2.6507e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.6224e-05 - val_loss: 2.5175e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.5497e-05 - val_loss: 2.4285e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.5284e-05 - val_loss: 2.4189e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.4791e-05 - val_loss: 2.5150e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 6s 16us/sample - loss: 2.4911e-05 - val_loss: 2.5483e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.4599e-05 - val_loss: 2.3094e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 6s 16us/sample - loss: 2.4231e-05 - val_loss: 2.4593e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.4331e-05 - val_loss: 2.3534e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.4215e-05 - val_loss: 2.3110e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.3810e-05 - val_loss: 2.3517e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.4403e-05 - val_loss: 2.5819e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.3688e-05 - val_loss: 2.2689e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.3837e-05 - val_loss: 2.3328e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.3849e-05 - val_loss: 2.3519e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.3708e-05 - val_loss: 2.2926e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.3698e-05 - val_loss: 2.4181e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 0.0273 - val_loss: 1.7953e-04\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 1.1449e-04 - val_loss: 7.1636e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 5.5764e-05 - val_loss: 4.6654e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 4.2603e-05 - val_loss: 3.9938e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 3.8229e-05 - val_loss: 3.6793e-05\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410270/410270 [==============================] - 6s 15us/sample - loss: 3.5596e-05 - val_loss: 3.4435e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 3.3383e-05 - val_loss: 3.2361e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 3.1142e-05 - val_loss: 3.0263e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.9339e-05 - val_loss: 2.8559e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.8182e-05 - val_loss: 2.7840e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.7446e-05 - val_loss: 2.9899e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.6754e-05 - val_loss: 2.7153e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.6292e-05 - val_loss: 2.9018e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.6008e-05 - val_loss: 2.5313e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.5690e-05 - val_loss: 2.4744e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.5108e-05 - val_loss: 2.5142e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.4716e-05 - val_loss: 2.4600e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.4708e-05 - val_loss: 2.5789e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.4476e-05 - val_loss: 2.4191e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.4401e-05 - val_loss: 2.3760e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 9s 23us/sample - loss: 4.8966e-04 - val_loss: 3.6806e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 3.1710e-05 - val_loss: 2.9161e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 2.8353e-05 - val_loss: 2.6243e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.7242e-05 - val_loss: 2.7725e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.6733e-05 - val_loss: 2.4121e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 2.8108e-05 - val_loss: 2.5455e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.7068e-05 - val_loss: 3.0277e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 2.7274e-05 - val_loss: 2.4236e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.6685e-05 - val_loss: 2.3920e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 2.6806e-05 - val_loss: 2.6366e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.6068e-05 - val_loss: 2.5450e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.5961e-05 - val_loss: 2.3129e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 10s 25us/sample - loss: 2.5472e-05 - val_loss: 2.6732e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 2.5475e-05 - val_loss: 2.2818e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.5183e-05 - val_loss: 2.6498e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.4867e-05 - val_loss: 2.3103e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.4537e-05 - val_loss: 2.6243e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 9s 22us/sample - loss: 2.4835e-05 - val_loss: 2.6361e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.4275e-05 - val_loss: 2.3148e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 2.4519e-05 - val_loss: 2.3004e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 9s 21us/sample - loss: 6.5048e-04 - val_loss: 3.5119e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 3.0977e-05 - val_loss: 3.0126e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.8814e-05 - val_loss: 2.7594e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.8067e-05 - val_loss: 2.6537e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 2.8026e-05 - val_loss: 2.4611e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 2.8828e-05 - val_loss: 4.1223e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 2.7288e-05 - val_loss: 2.7196e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 2.7449e-05 - val_loss: 4.5486e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 2.8359e-05 - val_loss: 2.7940e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 2.6229e-05 - val_loss: 2.7081e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 2.6403e-05 - val_loss: 2.3620e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 2.6493e-05 - val_loss: 2.4093e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 2.6114e-05 - val_loss: 2.2968e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.6018e-05 - val_loss: 3.6187e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 2.5632e-05 - val_loss: 2.9522e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 2.5260e-05 - val_loss: 2.2805e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 2.5852e-05 - val_loss: 2.2906e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 2.4963e-05 - val_loss: 3.0763e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 2.5223e-05 - val_loss: 2.3075e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 2.4682e-05 - val_loss: 2.4002e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 9.3254e-04 - val_loss: 5.4681e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 4.1639e-05 - val_loss: 3.9167e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 3.6731e-05 - val_loss: 3.3840e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 6s 16us/sample - loss: 3.8908e-05 - val_loss: 3.5845e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 6s 16us/sample - loss: 4.0590e-05 - val_loss: 3.7732e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 3.9270e-05 - val_loss: 2.8976e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 3.9111e-05 - val_loss: 3.5073e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 6s 16us/sample - loss: 3.8329e-05 - val_loss: 3.7198e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 6s 16us/sample - loss: 3.8197e-05 - val_loss: 4.8894e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 3.7240e-05 - val_loss: 2.7096e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 3.6509e-05 - val_loss: 5.3875e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 3.7589e-05 - val_loss: 2.6952e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 3.5555e-05 - val_loss: 2.8843e-05\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410270/410270 [==============================] - 7s 16us/sample - loss: 3.5058e-05 - val_loss: 4.6887e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 3.5344e-05 - val_loss: 2.7249e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 6s 16us/sample - loss: 3.5452e-05 - val_loss: 2.6185e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 3.4183e-05 - val_loss: 3.4195e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 3.5642e-05 - val_loss: 2.7437e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 3.3581e-05 - val_loss: 2.4907e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 6s 16us/sample - loss: 3.4762e-05 - val_loss: 3.2910e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 5.0499e-04 - val_loss: 4.7897e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 3.7028e-05 - val_loss: 3.2159e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 3.0530e-05 - val_loss: 2.8498e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.8447e-05 - val_loss: 2.9884e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.7330e-05 - val_loss: 2.5453e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.7505e-05 - val_loss: 2.4811e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.6562e-05 - val_loss: 3.2021e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.6789e-05 - val_loss: 2.6463e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.6016e-05 - val_loss: 2.3742e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.5887e-05 - val_loss: 2.4828e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.5900e-05 - val_loss: 2.5325e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.5457e-05 - val_loss: 2.3938e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.5824e-05 - val_loss: 2.3402e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.5633e-05 - val_loss: 2.4710e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.5033e-05 - val_loss: 2.4053e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.5085e-05 - val_loss: 2.3577e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.4680e-05 - val_loss: 2.5747e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.4656e-05 - val_loss: 2.2741e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.4465e-05 - val_loss: 2.4838e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.4270e-05 - val_loss: 2.6792e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 8s 20us/sample - loss: 9.0105e-04 - val_loss: 4.3608e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 3.2668e-05 - val_loss: 2.9447e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 2.8901e-05 - val_loss: 2.9021e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 2.7264e-05 - val_loss: 2.6081e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 2.6413e-05 - val_loss: 2.6586e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 2.6093e-05 - val_loss: 4.4899e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.6107e-05 - val_loss: 2.3956e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.5664e-05 - val_loss: 2.3907e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 2.5293e-05 - val_loss: 2.6955e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.5667e-05 - val_loss: 2.3835e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.5054e-05 - val_loss: 2.5286e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 2.4948e-05 - val_loss: 2.2802e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 8s 19us/sample - loss: 2.4485e-05 - val_loss: 2.9895e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 2.4190e-05 - val_loss: 2.3203e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 2.4407e-05 - val_loss: 2.2258e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 6s 16us/sample - loss: 2.3719e-05 - val_loss: 2.3420e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 6s 16us/sample - loss: 2.4423e-05 - val_loss: 2.2294e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 2.3845e-05 - val_loss: 2.2091e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.3721e-05 - val_loss: 2.7001e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 2.3803e-05 - val_loss: 2.2922e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 8s 18us/sample - loss: 0.0011 - val_loss: 5.4781e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 4.4623e-05 - val_loss: 4.0188e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 3.6276e-05 - val_loss: 3.3188e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 3.2321e-05 - val_loss: 2.9725e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 3.0769e-05 - val_loss: 3.4585e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 3.0247e-05 - val_loss: 2.9526e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 3.0223e-05 - val_loss: 2.8079e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.9208e-05 - val_loss: 3.0869e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.9393e-05 - val_loss: 2.8910e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.8255e-05 - val_loss: 4.9634e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.8310e-05 - val_loss: 2.7052e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.7607e-05 - val_loss: 2.8877e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.7766e-05 - val_loss: 2.8127e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 2.7065e-05 - val_loss: 2.4327e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 2.7273e-05 - val_loss: 2.4598e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 2.6749e-05 - val_loss: 4.3428e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 2.6802e-05 - val_loss: 3.3616e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 6s 16us/sample - loss: 2.6956e-05 - val_loss: 3.1620e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 6s 16us/sample - loss: 2.6464e-05 - val_loss: 2.4796e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.6559e-05 - val_loss: 2.3761e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 0.0013 - val_loss: 7.6451e-05\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410270/410270 [==============================] - 6s 15us/sample - loss: 4.7983e-05 - val_loss: 3.5092e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 3.2019e-05 - val_loss: 3.2304e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.9765e-05 - val_loss: 2.8353e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 6s 16us/sample - loss: 2.8214e-05 - val_loss: 2.6808e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.7001e-05 - val_loss: 2.5382e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 2.6125e-05 - val_loss: 2.9592e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.5845e-05 - val_loss: 2.9177e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.6148e-05 - val_loss: 2.3798e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.5418e-05 - val_loss: 2.3819e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.4957e-05 - val_loss: 2.3836e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.4850e-05 - val_loss: 2.4199e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.5005e-05 - val_loss: 2.4383e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.4747e-05 - val_loss: 2.3330e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.4738e-05 - val_loss: 2.4331e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 7s 16us/sample - loss: 2.4550e-05 - val_loss: 2.4647e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 2.4461e-05 - val_loss: 2.2910e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 2.4023e-05 - val_loss: 2.3032e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.4484e-05 - val_loss: 2.6401e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.4261e-05 - val_loss: 2.3025e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 7s 17us/sample - loss: 0.0011 - val_loss: 7.6083e-05\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 4.9096e-05 - val_loss: 3.4947e-05\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 6s 13us/sample - loss: 3.3155e-05 - val_loss: 3.1812e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 3.0400e-05 - val_loss: 2.9228e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.8326e-05 - val_loss: 2.7779e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.6968e-05 - val_loss: 3.0931e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.6077e-05 - val_loss: 2.4348e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.5830e-05 - val_loss: 2.5497e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.5791e-05 - val_loss: 3.1336e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.5632e-05 - val_loss: 2.3689e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.5075e-05 - val_loss: 2.3197e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.4613e-05 - val_loss: 2.3133e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.5174e-05 - val_loss: 2.2942e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.4471e-05 - val_loss: 2.2829e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 6s 13us/sample - loss: 2.4454e-05 - val_loss: 2.9946e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.4205e-05 - val_loss: 2.3411e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.4111e-05 - val_loss: 2.9315e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.4165e-05 - val_loss: 2.2277e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.3871e-05 - val_loss: 2.2367e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.3568e-05 - val_loss: 2.2619e-05\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/20\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 0.0212 - val_loss: 3.7674e-04\n",
      "Epoch 2/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.3002e-04 - val_loss: 1.4945e-04\n",
      "Epoch 3/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 1.1720e-04 - val_loss: 9.8980e-05\n",
      "Epoch 4/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 8.3698e-05 - val_loss: 7.0911e-05\n",
      "Epoch 5/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 5.9079e-05 - val_loss: 5.0702e-05\n",
      "Epoch 6/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 4.3118e-05 - val_loss: 3.8479e-05\n",
      "Epoch 7/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 3.4740e-05 - val_loss: 3.4921e-05\n",
      "Epoch 8/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 3.1459e-05 - val_loss: 3.0261e-05\n",
      "Epoch 9/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.9737e-05 - val_loss: 3.0215e-05\n",
      "Epoch 10/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.8300e-05 - val_loss: 2.7600e-05\n",
      "Epoch 11/20\n",
      "410270/410270 [==============================] - 6s 15us/sample - loss: 2.7401e-05 - val_loss: 2.6222e-05\n",
      "Epoch 12/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.6729e-05 - val_loss: 2.5638e-05\n",
      "Epoch 13/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.6088e-05 - val_loss: 2.6659e-05\n",
      "Epoch 14/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.5608e-05 - val_loss: 2.6039e-05\n",
      "Epoch 15/20\n",
      "410270/410270 [==============================] - 6s 13us/sample - loss: 2.5160e-05 - val_loss: 2.6836e-05\n",
      "Epoch 16/20\n",
      "410270/410270 [==============================] - 6s 13us/sample - loss: 2.5016e-05 - val_loss: 2.3870e-05\n",
      "Epoch 17/20\n",
      "410270/410270 [==============================] - 6s 13us/sample - loss: 2.4749e-05 - val_loss: 2.5464e-05\n",
      "Epoch 18/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.4830e-05 - val_loss: 2.5042e-05\n",
      "Epoch 19/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.4294e-05 - val_loss: 2.3246e-05\n",
      "Epoch 20/20\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.4010e-05 - val_loss: 2.3249e-05\n",
      "******************************************************************************************************************\n",
      "******************************************************************************************************************\n",
      "the final model is the one with :  {'lstm_units': 128, 'hidden_dense_layers': 1, 'dense_units': 64, 'act_fct': 'linear'}\n",
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_54 (LSTM)               (None, 1, 128)            73728     \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 1, 64)             8256      \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 1, 1)              65        \n",
      "=================================================================\n",
      "Total params: 82,049\n",
      "Trainable params: 82,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410270/410270 [==============================] - 13s 31us/sample - loss: 0.0821 - val_loss: 1.0479e-04\n",
      "Epoch 2/40\n",
      "410270/410270 [==============================] - 12s 28us/sample - loss: 6.1441e-05 - val_loss: 4.3355e-05\n",
      "Epoch 3/40\n",
      "410270/410270 [==============================] - 11s 27us/sample - loss: 3.8310e-05 - val_loss: 3.5352e-05\n",
      "Epoch 4/40\n",
      "410270/410270 [==============================] - 12s 29us/sample - loss: 3.4111e-05 - val_loss: 3.3299e-05\n",
      "Epoch 5/40\n",
      "410270/410270 [==============================] - 12s 30us/sample - loss: 3.2166e-05 - val_loss: 3.1060e-05\n",
      "Epoch 6/40\n",
      "410270/410270 [==============================] - 12s 30us/sample - loss: 3.0386e-05 - val_loss: 2.9308e-05\n",
      "Epoch 7/40\n",
      "410270/410270 [==============================] - 13s 32us/sample - loss: 2.8771e-05 - val_loss: 2.8751e-05\n",
      "Epoch 8/40\n",
      "410270/410270 [==============================] - 12s 29us/sample - loss: 2.7906e-05 - val_loss: 2.8697e-05\n",
      "Epoch 9/40\n",
      "410270/410270 [==============================] - 12s 29us/sample - loss: 2.7271e-05 - val_loss: 2.6251e-05\n",
      "Epoch 10/40\n",
      "410270/410270 [==============================] - 12s 28us/sample - loss: 2.6468e-05 - val_loss: 3.6572e-05\n",
      "Epoch 11/40\n",
      "410270/410270 [==============================] - 12s 28us/sample - loss: 2.7219e-05 - val_loss: 2.5270e-05\n",
      "Epoch 12/40\n",
      "410270/410270 [==============================] - 12s 29us/sample - loss: 2.7700e-05 - val_loss: 2.6854e-05\n",
      "Epoch 13/40\n",
      "410270/410270 [==============================] - 12s 28us/sample - loss: 2.8178e-05 - val_loss: 4.0388e-05\n",
      "Epoch 14/40\n",
      "410270/410270 [==============================] - 12s 29us/sample - loss: 2.7887e-05 - val_loss: 2.4802e-05\n",
      "Epoch 15/40\n",
      "410270/410270 [==============================] - 12s 30us/sample - loss: 2.8480e-05 - val_loss: 2.5335e-05\n",
      "Epoch 16/40\n",
      "410270/410270 [==============================] - 12s 29us/sample - loss: 2.7200e-05 - val_loss: 4.5174e-05\n",
      "Epoch 17/40\n",
      "410270/410270 [==============================] - 12s 29us/sample - loss: 2.7388e-05 - val_loss: 2.4439e-05\n",
      "Epoch 18/40\n",
      "410270/410270 [==============================] - 12s 28us/sample - loss: 2.8511e-05 - val_loss: 3.5255e-05\n",
      "Epoch 19/40\n",
      "410270/410270 [==============================] - 12s 29us/sample - loss: 2.7210e-05 - val_loss: 2.6856e-05\n",
      "Epoch 20/40\n",
      "410270/410270 [==============================] - 17s 41us/sample - loss: 2.7113e-05 - val_loss: 2.5680e-05\n",
      "Epoch 21/40\n",
      "410270/410270 [==============================] - 14s 33us/sample - loss: 2.6849e-05 - val_loss: 2.4686e-05\n",
      "Epoch 22/40\n",
      "410270/410270 [==============================] - 11s 28us/sample - loss: 2.7187e-05 - val_loss: 2.3889e-05\n",
      "Epoch 23/40\n",
      "410270/410270 [==============================] - 13s 32us/sample - loss: 2.7382e-05 - val_loss: 2.3112e-05\n",
      "Epoch 24/40\n",
      "410270/410270 [==============================] - 15s 36us/sample - loss: 2.6321e-05 - val_loss: 2.5398e-05\n",
      "Epoch 25/40\n",
      "410270/410270 [==============================] - 17s 41us/sample - loss: 2.7368e-05 - val_loss: 2.3006e-05\n",
      "Epoch 26/40\n",
      "410270/410270 [==============================] - 13s 32us/sample - loss: 2.7292e-05 - val_loss: 2.3025e-05\n",
      "Epoch 27/40\n",
      "410270/410270 [==============================] - 11s 28us/sample - loss: 2.5759e-05 - val_loss: 2.2949e-05\n",
      "Epoch 28/40\n",
      "410270/410270 [==============================] - 14s 34us/sample - loss: 2.6947e-05 - val_loss: 2.7170e-05\n",
      "Epoch 29/40\n",
      "410270/410270 [==============================] - 14s 34us/sample - loss: 2.6338e-05 - val_loss: 2.4863e-05\n",
      "Epoch 30/40\n",
      "410270/410270 [==============================] - 13s 31us/sample - loss: 2.7550e-05 - val_loss: 2.6390e-05\n",
      "Epoch 31/40\n",
      "410270/410270 [==============================] - 13s 31us/sample - loss: 2.5750e-05 - val_loss: 2.3136e-05\n",
      "Epoch 32/40\n",
      "410270/410270 [==============================] - 12s 30us/sample - loss: 2.6655e-05 - val_loss: 2.9184e-05\n",
      "Epoch 33/40\n",
      "410270/410270 [==============================] - 12s 29us/sample - loss: 2.6060e-05 - val_loss: 2.4507e-05\n",
      "Epoch 34/40\n",
      "410270/410270 [==============================] - 12s 30us/sample - loss: 2.6540e-05 - val_loss: 4.2077e-05\n",
      "Epoch 35/40\n",
      "410270/410270 [==============================] - 12s 30us/sample - loss: 2.5867e-05 - val_loss: 2.5744e-05\n",
      "Epoch 36/40\n",
      "410270/410270 [==============================] - 12s 30us/sample - loss: 2.5953e-05 - val_loss: 2.6565e-05\n",
      "Epoch 37/40\n",
      "410270/410270 [==============================] - 13s 31us/sample - loss: 2.6074e-05 - val_loss: 2.2896e-05\n",
      "Epoch 38/40\n",
      "410270/410270 [==============================] - 13s 31us/sample - loss: 2.6013e-05 - val_loss: 2.2532e-05\n",
      "Epoch 39/40\n",
      "410270/410270 [==============================] - 13s 31us/sample - loss: 2.5543e-05 - val_loss: 2.2562e-05\n",
      "Epoch 40/40\n",
      "410270/410270 [==============================] - 11s 28us/sample - loss: 2.6256e-05 - val_loss: 2.6548e-05\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA84AAADYCAYAAAA6crpDAAAgAElEQVR4Xu3dCZyN1f/A8e/YIkk1Y5coWzQqKXuoLMWEkrL0b6F+lTKoyL5LEeqXfiW/dmknLbZEtoRQSLJlKyHZd+b/+h6/O+6Me+fe+9y5M8+593NeL6808zznOed9nuc633uWJy4lJSVFSAgggAACCCCAAAIIIIAAAggg4FMgjsCZOwMBBBBAAAEEEEAAAQQQQAAB/wIEztwdCCCAAAIIIIAAAggggAACCGQgQODM7YEAAggggAACCCCAAAIIIIAAgTP3AAIIIIAAAggggAACCCCAAALOBBhxdubGWQgggAACCCCAAAIIIIAAAjEiQOAcIw1NNRFAAAEEEEAAAQQQQAABBJwJEDg7c+MsBBBAAAEEEEAAAQQQQACBGBEgcI6RhqaaCCCAAAIIIIAAAggggAACzgQInJ25cRYCCCCAAAIIIIAAAggggECMCBA4x0hDU00EEEAAAQQQQAABBBBAAAFnAgTOztw4CwEEEEAAAQQQQAABBBBAIEYECJxjpKGpJgIIIIAAAggggAACCCCAgDMBAmdnbpyFAAIIIIAAAggggAACCCAQIwIEzjHS0FQTAQQQQAABBBBAAAEEEEDAmQCBszM3zkIAAQQQQAABBBBAAAEEEIgRAQLnGGloqokAAggggAACCCCAAAIIIOBMgMDZmRtnIYAAAggggAACCCCAAAIIxIgAgXOMNDTVRAABBBBAAAEEEEAAAQQQcCZA4OzMjbMQQAABBBBAAAEEEEAAAQRiRIDAOUYammoigAACCCCAAAIIIIAAAgg4EyBwdubGWQgggAACCCCAAAIIIIAAAjEiQOAcIw1NNRFAAAEEEEAAAQQQQAABBJwJEDg7c+MsBBBAAAEEEEAAAQQQQACBGBEgcI6RhqaaCCCAAAIIIIAAAggggAACzgQInJ25WXXW0aNHZenSpVK0aFHJlSuXVWWnsAgggAACCCCAAAIIxLLAyZMnZceOHVKtWjXJmzdvLFNka90JnLOVP2suPn/+fKlbt27WXIyrIIAAAggggAACCCCAQKYLzJs3T+rUqZPp+ZJhcAIEzsE5WX3U+vXrpVy5cqIPW8mSJa2uC4VHAAEEEEAAAQQQQCCWBLZt22YGwdatWydly5aNpaq7qq4Ezq5qjsgU5vfff5cyZcrIpk2bpHTp0pG5CLkigAACCCCAAAIIIIBApgvQl890UkcZEjg7YrPrJB42u9qL0iKAAAIIIIAAAggg4BGgL++Oe4HA2R3tENFS8LBFlJfMEUAAAQQQQAABBBCImAB9+YjRhpQxgXNIXGcP3rhxoyQnJ8vs2bMlT548kpSUJKNGjZL4+PiAOc6cOVN69eolq1atkkKFCknHjh2ld+/ekjNnztRzDx06JEOHDpWPPvpItm/fLsWKFZM77rhD+vfvLwUKFAh4De8DeNhC4uJgBBBAAAEEEEAAAQRcI0Bf3h1NQeDsoB32798viYmJJugdOHCgaJDbo0cPE9wuWLBA4uLi/Oa6ZMkSqV27trRq1coEzBo867kahA8fPjz1vDZt2sgXX3whQ4YMkauvvlpWrlwpffr0kVtuuUU+++yzkErthodt5/6jMnzqr7J97xEZfmcVKZOQP6Q6cDACCCCAAAIIIIAAArEo4Ia+fCy6p68zgbODu2DEiBEmiNVR5xIlSpgcFi5caALiKVOmmNFnf6lp06aydetWWbFiheTIkcMcNmzYMBOA68hyQkKCHDt2TC644ALp2bOnDBo0KDUr/bsep4F7/vzBB55ueNj2HDouVQfPNHV564HrpX6Fwg7kOQUBBBBAAAEEEIhOgdOnT8vu3bvl6NGjon8nRb+AxgL6Xmbt/3viAl+1dkNfPvpbI3ANCZwDG51zRP369SV37tyiU669k+5c3bBhQxk3bpzPXI8fP26mWffr189MzfakzZs3m92uJ0yYIG3btpXDhw+bwHnkyJHSrVu31ONeeukl6dKlixw4cMC6wDklJUUq9p0mx06elmEtE6Vt9VIO5DkFAQQQQAABBBCIPgENlHUA5eDBg6aPqcv3MprBGH0CsVcj7RufOnVKTpw4Yfr9OhjnL3gmcHbH/UHg7KAdihQpIjqVesyYMWnO1tFkHQ3W9yX7SmvWrJFKlSrJpEmTpEWLFmkO0RFkDZIHDx5sfn7ffffJd999JxMnTjTTwnVKt14zo8DcX1Xc8rDdNHKObNx9SB5vUFaealzBgTynIIAAAggggAAC0Sewc+dO+fvvv80yQB19JMWOgM4y2LVrl9knqXBh3zMy3dKXj51W8V1TAmcHd4BuBqabew0YMCDN2e3bt5fly5fL6tWrfebqmc6tG4rpqLV3KlmypDRv3lzGjh1rfnzy5El59NFHZfz48amH6Wj0O++8k2YTMV8X2rt3r+gfT/K8ND273+PcfvwPMn/9brmjagkZ1foaB/KcggACCCCAAAIIRJ/Ali1bRGcmli1bNvoqR40CCqxfv95sNlyqlO8ZmQTOAQmz5AACZwfMemPrVGvd4do7tWvXzqxd9hc468ZhderUkTlz5ki9evXSnKvTM3QU2hM4P/300/L222+bNc46Sq2bg+kUb91U7LXXXsuw1BrQ61ro9Cm7A+fun/wkHy3dJjUuv0Q+eLimA3lOQQABBBBAAAEEok9AAyOduqvL/kixJ6B9dJ2ar0s3fSUCZ3fcEwTODtoh0lO1dVq2Ts/+8MMPpXXr1qklfO+99+Tee+81QfRVV13lt+RuHXEe881vMuabdVLqkvNlbvcGDuQ5BQEEEEAAAQQQiD4BDYw0+Qucoq/G1MhbIFD7Ezi7434hcHbQDjrNWkedZ8yYkebsYDcH05FqnertSek3B9N3N999992ydu1aKV++fOpxOpKtAbO+jqply5ZBl9wtD9tHS7dK909+ltw542Tt4FslRw7/r+0KunIciAACCCCAAAIIWC4QKHCyvHoUP4BAoPZ3S18+1huSwNnBHaC7XetUbZ1WUbx4cZPDokWLpGbNmgFfR9WsWTPzOipdC+3ZOU/f36zBtOd1VIsXL5bq1avL+++/bzYE8ySdun3//febc6+5Jvg1wm552Oav2y3t//uDqc7iXjdL4QvzOtDnFAQQQAABBBBAILoEAgVOttV28uTJouu2O3funKlFf+utt+SBBx4wfWndHyjcpNOjdWNefc1sdqZA7e+Wvnx2Grnh2gTODlpBd87WqdS6852uJz5y5Ih0795dihYtKrqO2fP6AM9aY++1xRoU6zpnnYLdoUMHs1t2jx49zAeLBtCadGt6PWbdunUm/8qVK8vPP/9s1i1XqVJFdHOxUF5R4JaHbeOug3LTC9+ZOk7uVFuuufQiB/qcggACCCCAAAIIRJdAoMDJttrqQM/8+fNFN73KzKS7T2/YsEGqVq1qZn+GmwicwxWMrfMJnB22tz60ycnJZqMvfd9eUlKSjB492mwl70m+Amf9nb7/uWfPniZo1lcOPPTQQ+abLn1nnyfpB4OeP3XqVPnzzz/Nu930dVc6Mn3JJZeEVGq3BM5HT5wy73LW9Eq7qnJbYrGQ6sHBCCCAAAIIIIBANArEcuCsA1D58uXLlmYlcM4WdmsvSuBsbdMFX3C3BM5a4usGz5S/Dx2XPk2vlI51Lw++EhyJAAIIIIAAAghEqUA0Bc462qzLC72Tvk1GB5t0UGjIkCHy448/yuOPPy5Lly41My/15y+++KJMnDjR7PGjAa3Osnz22WfNUkhP8jVV2xP86gj0v//9b9GZoTpzU99CE2g6t6/A+euvvzbl0c148+fPL7feequMGDHCzCz1JK3fCy+8YEbU9br6GrG+ffuaV8tq+uqrr8ybcX755RdTl8suu8zMLtXBMl8pUPu7qS8fpY9gUNUicA6Kye6D3PSwJf17vqzcvk8eqF1a+idVthuW0iOAAAIIIIAAApkgEChwyoRLZFkWOitTg0RdZvjxxx+b61544YXm9aoakOqa4iuuuMIEzhoc6+906nW3bt3MJri6s/jRo0dNEK1vmNEgW5dIavIXOOv7j3X/n4cfflj27Nlj8tJzvv322wzrnT5w1pmeuh+RziTVIHfnzp1mlujFF19synH++efLvHnz5MYbb5SuXbuaY48dO2bqqm/d0S8NtP5aV12WqW/D0T2NNIDW93Q/9dRTBM5Zdidm/oUInDPf1HU5uilwfvidpTLjl7+kceUi8tq91VxnRYEQQAABBBBAAIGsFvAVOOsSt81/H87qopxzvcviz5e8uc8uJwymQP7WOHuWMb755psmyPSXdL8ffa/11VdfLbfccosZjc4ocPbsB+TZeHfUqFHy5JNPyl9//WX2JPKX0gfO1apVkxMnTsiKFStS9xP6/vvvpVatWvLqq6/Kv/71L9FNgocNG2YCdF/pk08+kbvuukv27dtnvhQIJgX64sRNfflg6hOtxxA4R2vLetXLTQ/bgCmr5a2Fv0tiiYLyxRN1YkCfKiKAAAIIIIAAAhkL+Aqc1u44II3HzM12uuldbpQKRQuEVI5AgbPu5aP7/HgnfUONBtY6srt79+7UXzVu3FimTTuzR46/EWcdYdap0540ffp0adKkiSxZskQ0GA4mcD548KAJdHVEXN+e4510FLx27doyYcIEs0nvTTfdJO3bt5f/+7//M1PJL7jggtTDdXNfHXFu1KiRCbR12nig/YkInEO6vbLtYALnbKPPugu7KXB+fe5GGfr1Gkm4II8s7dMw6xC4EgIIIIAAAggg4FKBWAqcNTDVEWXvtHnzZjO1Wqdq6zRvXZucN29eE3gWKFDArI/OKHBO/0opPb5BgwZmWrUGrsEEztu2bZNLL71Uxo8fb958451q1KhhpmvrVG5NH3zwgRkF17fl5MqVy2zgO2bMGNEp45p0I2Bdn607i58+fVrq169vNhH2TDlPXx4CZ5c+mOmKReBsRzuFVUo3Bc5f/fyndHp/manPr4ObhDz1JywITkYAAQQQQAABBFwoEEtTtXVzsJMnT6Zphddff92sT/7jjz+kWLGzb13RTbc0iM6KwDnYEWfvgu/du9cE0zotXMs6d27aGQKHDx+WWbNmmdfWHjp0yLzb2lcicHbhQ+mjSATOdrRTWKV0U+C8fMs/0vKVhaY+s5+qL2US8odVN05GAAEEEEAAAQRsFwgUONlWPx0p1p2ldRTXO3l21U4fOOvobZcuXeTvv/9OndbsWVvs2ZFb88loV219tasnORlx1nN9rXHWKeQ6HduzxtlXW+hUcS2bv3XPL730knmNrb91z4Ha3019edvuxcwsL4FzZmq6NC83PWw79x+VG4bNMlITOlaX2mXTrm9xKSHFQgABBBBAAAEEIiYQKHCK2IUjlLFOW9Zg8o033hDduEvXDleoUCH1dVTpA+dVq1aZXbFvu+02M1Vbp25rkK1Jd+DOihFnvZb3rto6Aq67avfq1cuUf9myZWZX7f79+5uf61RwfUWVvpLqmWeeMeuedQq3vgZLp4hrXUqUKGFG0fv16yfx8fGiQbivFKj93dSXj9AtY0W2BM5WNFN4hXTTw3b6dIpU6DtVTpxKkedbVZHW1S4Nr3KcjQACCCCAAAIIWC4QKHCyrXoHDhyQTp06mU29dKMvfX2T93uc0wfOWr/333/fBMs6nblixYpm52rdHVuPzarAWcuhI+We9zhroKwBsO6k7XmPs/5evxjQV1DpVG2dWt6yZUvz3mZdj60j5Vp2DbS17oUKFRLd4Gzo0KFp3gXt3aaB2t9NfXnb7sXMLC+Bc2ZqujQvtz1sdZ//VrbuOSJdbykvybeUc6kaxUIAAQQQQAABBLJGIFDglDWl4CrZJRCo/d3Wl88up+y+LoFzdrdAFlzfbQ/b3a99Lz9s2iN3V7tUnmtVJQsEuAQCCCCAAAIIIOBegUCBk3tLTskyQyBQ+7utL58ZdbYxDwJnG1stxDK77WHr9uEK+Wz5dqlbLkHe7VA9xNpwOAIIIIAAAgggEF0CgQKn6KottUkvEKj93daXj9UWJHCOgZZ328M2cvpaeXn2erm8UH759sn6MdACVBEBBBBAAAEEEPAvEChwwi66BQK1v9v68tHdGv5rR+AcAy3vtodtwg+bpfekVZI3dw5ZM6iJxMXFxUArUEUEEEAAAQQQQMC3QKDACbfoFgjU/m7ry0d3axA4x2r7mnq77WGbvXanPPDmElO2ZX0byiX588R0+1B5BBBAAAEEEIhtgUCBU2zrRH/tA7W/2/ry0d8ivmvIiHMMtLzbHrbf/jogjUbPNfJfPlFHripRMAZagSoigAACCCCAAAK+BQIFTrhFt0Cg9ndbXz66W8N/7QicY6Dl3fawHTh6QhIHzDDy4+69ThpVLhoDrUAVEUAAAQQQQAABAmfugXMFCJztuCsInO1op7BK6bbAWStTZcB02X/0pAxIqiT31y4TVv04GQEEEEAAAQQQsFkgUOBkc90oe2CBQO3vxr584FpF3xEEztHXpufUyI0PW5Mxc+XXHQfk4Rsvl163XRkDrUAVEUAAAQQQQAAB3wKBAifcolsgUPu7sS8f3S3iu3YEzjHQ6m582B58a4l8++tOaVqlmIxtWzUGWoEqIoAAAggggAACBM7cA+cKEDjbcVcQONvRTmGV0o2Bc5/JK+W9RVukaqmL5LPHaodVP05GAAEEEEAAAQRsFggUONlWt8mTJ8uWLVukc+fOESl6KPm/9dZb8sADD8jWrVulZMmSESlPuJkGan839uXDrbON5xM429hqIZbZjQ/bK3PWy/PT1krRC/PKol43h1gjDkcAAQQQQAABBKJHIFDgZFtN77//fpk/f76sX78+IkUPJX8C54g0QUxmSuAcA83uxsD58xXbJfmDFRIXJ/LbkFsld84cMdASVBEBBBBAAAEEEDhXgMA5tLuCwDk0L47OHAEC58xxdHUubgycl/y+R+569XvjNq97A7n0kvNdbUjhEEAAAQQQQACBSAlEU+CsQe3bb7+dhqpevXoyZ84c8zMdhe7Vq5d88803cuTIEbn22mvl+eeflzp16qSe8/3335tjli9fLidOnDBTrO+9917p06ePBMo/fRv5GnE+fvy4DBgwQN577z3566+/5LLLLpNHH31Uunbtmnr6vn37pEePHvLll1/Krl275JJLLpHrrrvO1C0+Pt6Uq1+/fjJx4kT5888/pWDBgpKYmCj/+c9/pHz58iHdKoHa3419+ZAqGCUHEzhHSUNmVA03Pmzb/jksdZ6bbYr94cM1pPrl8THQElQRAQQQQAABBBA4V8Bn4HTiqMiejdnPdcnlIrnzBl2ODRs2mLXNP//8s3z88cfmvAsvvFAqVaokmzdvNsGnBqrdu3c3P3/11Vdl+vTpsmjRIrnmmmvkwIEDUqpUKalRo4Y8/vjjki9fPhNsb9q0SZ599lnJKH9fhfQVOLdp00Y+++wzEzxrefT6o0aNkr59+8qgQYNMNh06dJCvvvrKXPOKK66QnTt3mmBfg3cN5AcPHizPPfecDB8+3ATM//zzj5mefvfdd8v1118ftJceSOAcEle2HUzg7JB+48aNkpycLLNnz5Y8efJIUlKSeeD0G6hAaebMmeZbtFWrVkmhQoWkY8eO0rt3b8mZM2eaUw8ePGgeyg8//NB8k6XHNm7cWP773/8GukSa37sxcD5x6rRU6DNVTqeIjL77aml5rTs3awgJmoMRQAABBBBAAAEHAj4Dp79+EflPTQe5ZfIpj34vUqRSSJn6m0r94IMPmiB1zZo1JmjWdOrUKbnqqqtM8PnRRx/J0qVLTeD5008/SZUqVXxeN5yp2tr/1muNHDlSnnzyydT8//Wvf8k777xj+twXXXSRKVOjRo1M/95XatasmYkBNAAPNxE4hyuYNecTODtw3r9/v3ngNJAdOHCgHDp0yEzlKFasmCxYsEDidOGun7RkyRKpXbu2tGrVygTM+vDquRqE6zdWnnT06FHRaS06NUSD6nLlyskff/xhvo0bM2ZMSKV2Y+CsFaj57Cz5c99RebpxBenUoGxIdeJgBBBAAAEEEEAgWgRiJXAuUaKEaMA5duzYNE2nU6Q//fRT09fdu3evlC5d2oxQd+nSRW688UYpWrRomuPDCZxfeeUV6dSpk2zbtk20PJ6kU8kbNGggM2bMkIYNG5op4VOmTJFnnnlGmjRpYvr+3n18Ha3WvruOnGudqlatKrly5XJ0SxI4O2LL8pMInB2QjxgxwkzT0FFnzwO3cOFCExDrA6ajz/5S06ZNzXb4K1askBw5zmyINWzYMBOAb9++XRISEszP9P/1G65ffvklzUPtoLhm+keZMmXMFBf9IHJLuvM/C+XHzf9Iu+qlZGjLRLcUi3IggAACCCCAAAJZKhBNU7UVzl9gmzt3bjl58qRPWx29PXbsmPndjz/+aKZRz5o1S3QwSUegtf+tQXRG+fvKOP1U7SFDhpgp2bpG2TvQ/fXXX+XKK6+UDz74wEy31inj2h/XmZ8aZGvwrgG3zhrVPryuk9a12TpKvW7dOrn44otNvYcOHWqml4eSCJxD0cq+YwmcHdjXr19f9MHXKdfeSYNT/YZq3LhxPnPVB6xAgQJmIwEdRfYkXe+hAe2ECROkbdu25scakN96660yfvx4ByVMe4pbA+cnJi6XL376QxpUKCRvPnBD2PUkAwQQQAABBBBAwEaBQIGTbXXyFzhr8HnzzTen2YTLUzcdzdX1xt5J+866blgHrHSWpr4bWqdRZ8WIs3c5fvvtN7NUUgNl/a9OOfdOWi4NsDWo7tmzZ+o66WDbLVD7u7UvH2z9ouU4AmcHLVmkSBHRTQXST5nW0WSdxj1v3jyfuep6Dp12MmnSJGnRokWaY/Lnzy/dunUza5o9gbT+XTdA0I0VUlJSzAfNiy++aEaPQ0lufdienbpGXvtuo1QoUkCmdz3zDSIJAQQQQAABBBCINYFAgZNtHrpeWDfW0pFa73TffffJsmXLzIiyjjAHm3RGZ/PmzVPXPfvL31d+6UecV69ebdYvp1/jrLtq67GeNc6+8tKdtTVo97fuWadr62BYqOueA7W/W/vywbZftBxH4OygJfVB12+UdAqJd2rfvr3ZNl8fSF/JM51bNxTTUWvvpLvz6QeCrvnQdcw1a9Y0o9P6Xw2odac+/QZLR7r1G7eMPmx0bYj+8ST90Kpbt67rpmq/vfB36T9ltRQ4L5esHNjYQUtwCgIIIIAAAgggYL9AoMDJthrq4JL2X9944w2pXLmy2QisQoUKZnBIp13r3j2PPfaY2Z169+7dJpDWTXJ10Ehf//T6669Ly5YtTRCqfWBd1qivjdLdtbUP7C//YAJnPUZneOqaau3LV6tWzaxrfuGFF8zItmdX7Vq1apmBLg2y8+bNa5Zj6gDW119/bWaFar9dX6WlwbLWTwfOdGr3yy+/LI888khITRao/QmcQ+KM2MEEzg5o9YHVqdb9+/dPc3a7du3M2mV/gbNuHKbvqNPNB3TjL++kU7P14dTA2XOcTmfRddSedRKeXQZ1LYW+y85f0g8BfXDTJ7etcZ75y1/y0DtLTTF/HtBILsyb20FrcAoCCCCAAAIIIGC3QKDAybba6fpgXQ88bdo0Exjr2mTPe5w1eNZli7q79p49e6Rw4cJmirYer7tYr1271qxB/uGHH0ywrFOzdQBI1w573o+cUf7prfy9x1n78d7vcdZA3vs9zrrpl5ZR+88681MD/6eeekruuececwkdsdZdwHV9s04p1xmhOhL+xBNPhNxcgdqfwDlk0oicQODsgDXSU7U9mxPceeed8sknn6QpoX546EOp743zl2wZcV79xz5p+tJ8U43pXW6UCkULOGgNTkEAAQQQQAABBOwWCBQ42V07Sh9IIFD7EzgHEsya3xM4O3DWadY66qzTOrxTsJuD6TdcOtXbk9JvDqa7/OmUD10znT5wLliwoFlboVNFgk1ufdj2Hj4u1ww6s8Ham/dfLw0qFg62ShyHAAIIIIAAAghEjUCgwClqKkpFfAoEan+39uVjrTkJnB20uE7N0KnaOnWjePHiJgfPuuRAr6PS97zp66h0LbTndVT6DjgNpr1fR3XHHXeIronWa3imai9evFiqV68u7777ruh66mCTWx82nfZSuf90OXz8lAxpcZW0r3FZsFXiOAQQQAABBBBAIGoEAgVOUVNRKkLgbPE9QODsoPF052x9CbquydD1xEeOHDEvP9c1ybo+2fNydM9aY++1xRr86jrn1q1bS4cOHcxGXz169JDOnTubl6h70sqVK02QrBsT6HoLnX6to9S6YZhuoHDeeecFXXK3Bs5agZtfmCMbdh2Sx+pfId2bVAy6ThyIAAIIIIAAAghEiwCBc7S0pLN6BGp/N/flndXYzrMInB22m74mKjk52Wx0oDtdJyUlyejRoyU+Pj41R1+Bs/5S3/+sO2Rr0JyQkCAPPfSQ2cVPdxP0ThqEa1CtgbKOOuvUbd3xTwP2UJKbH7Z7//uDzFu3W1pcU1zG3HNtKNXiWAQQQAABBBBAICoEAgVOUVFJKuFXIFD7u7kvH0vNSuAcA63t5oftmU9/lg+WbJUbylwiH/2rZgy0BlVEAAEEEEAAAQTSCmhfTZew6X45pNgT0NmpOmNVX7/lK7m5Lx9LrUXgHAOt7eaH7aVZ62TUzN+k5MX5ZH6Pm2KgNagiAggggAACCCCQVmDLli3mlUZly5aFJgYFPO+nLlWqFIGzi9ufwNnFjZNZRXNz4PzJj9vkqY9/klw54mTtkFslZ464zKo2+SCAAAIIIIAAAlYI7Ny5U/7++28pVKiQWcZHih0Bfc/1rl27zHJPf8sx3dyXj52WEiFwjoHWdvPDtnDDbmn7+g+mFRb1vFmKFswbAy1CFRFAAAEEEEAAgbMCp0+fNm9XOXjwoNk7R/e98Ww2i1N0CujU/FOnTom+hvaCCy6QEiVKpL5xJ32N3dyXj87W8W8hmOUAACAASURBVF0rAucYaG03P2y/7z4k9UfOMa3w6aO15LrLLo6BFqGKCCCAAAIIIIBAWgENnnX08ejRo6J/J0W/gL6aNm/evGaWgec1tb5q7ea+fPS30tkaEjjHQGu7+WE7euKUVOw7zbTCy22vlWZVzrwXm4QAAggggAACCCCAAAIibu7Lx1L7EDjHQGu7/WGrNuQb2X3wmPS6raI8fOMVMdAiVBEBBBBAAAEEEEAAgeAE3N6XD64W9h9F4Gx/GwasgdsftuYvz5eftu2T+2uVlgG3Vw5YHw5AAAEEEEAAAQQQQCBWBNzel4+VdiBwjoGWdvvD9uh7P8rUVTukYaUi8vr/VYuBFqGKCCCAAAIIIIAAAggEJ+D2vnxwtbD/KAJn+9swYA3c/rAN+uIXeWPBJqlc/EL5qnPdgPXhAAQQQAABBBBAAAEEYkXA7X35WGkHAucYaGm3P2zj522UIV+tkYvPzy3L+zWKgRahiggggAACCCCAAAIIBCfg9r58cLWw/ygCZ/vbMGAN3P6wTV35pzw6YZmpx5pBTSRfnpwB68QBCCCAAAIIIIAAAgjEgoDb+/Kx0AZaRwLnGGhptz9sP23dK83HLjAtMevJenJFoQtioFWoIgIIIIAAAggggAACgQXc3pcPXIPoOILAOTraMcNauP1h23XgmFw/9BtTh3c73CB1yxWKgVahiggggAACCCCAAAIIBBZwe18+cA2i4wgC5+hoR6sD59OnU6Riv2ly/ORpee7ORLn7+lIx0CpUEQEEEEAAAQQQQACBwAIEzoGNsuIIAuesUM7ma9jwsNUbMVs2/31YOt9cTro1LJ/NYlweAQQQQAABBBBAAAF3CNjQl3eHVGRLQeAcWV9X5G7Dw9Zm3CL5fuPfctd1JWXEXVe7wo1CIIAAAggggAACCCCQ3QI29OWz2ygrrk/gnBXK2XwNGx62Jz/6ST5dtk1ql42XCR1rZLMYl0cAAQQQQAABBBBAwB0CNvTl3SEV2VIQOEfW1xW52/CwjZqxVl76dr2UScgvs5+q7wo3CoEAAggggAACCCCAQHYL2NCXz26jrLg+gXNWKGfzNWx42D5YvEWe+Wyl5MmVQ9YObiJxcXHZrMblEUAAAQQQQAABBBDIfgEb+vLZrxT5EhA4R944269gw8P23W+75L43FhurpX1ukYQLzst2NwqAAAIIIIAAAggggEB2C9jQl89uo6y4PoFzVihn8zVseNjW7zwgt4yaa6S+eLyOJJYsmM1qXB4BBBBAAAEEEEAAgewXsKEvn/1KkS8BgXPkjbP9CjY8bIeOnZTK/acbq1fbXydNriqa7W4UAAEEEEAAAQQQQACB7BawoS+f3UZZcX0C56xQzuZr2PKwXTNohuw9fEL6NaskD9Ypk81qXB4BBBBAAAEEEEAAgewXsKUvn/1SkS0BgXNkfV2Ruy0P220vzpNf/twvHeuUkT7NKrnCjkIggAACCCCAAAIIIJCdArb05bPTKCuuTeDsUHnjxo2SnJwss2fPljx58khSUpKMGjVK4uPjA+Y4c+ZM6dWrl6xatUoKFSokHTt2lN69e0vOnDl9nrto0SKpVauW5MiRQ06ePBkw//QH2PKwdXx7qXyz5i+5LbGovNLuupDryQkIIIAAAggggAACCESbgC19+WhzT18fAmcHLbx//35JTEw0Qe/AgQPl0KFD0qNHDylWrJgsWLAgw1cpLVmyRGrXri2tWrUyAbMGz3quBuHDhw8/pzSnTp2SatWqyY4dO2TXrl1RHTj3+3yVvPP9Zrn60ovk8061HbQMpyCAAAIIIIAAAgggEF0CBM7uaE8CZwftMGLECOnTp4/oqHOJEiVMDgsXLjQB8ZQpU8zos7/UtGlT2bp1q6xYscKMIGsaNmyYCcC3b98uCQkJaU4dM2aMvPbaa3LHHXfIc889F9WB86vfbZDhU3+VwgXOk8W9b3HQMpyCAAIIIIAAAggggEB0CRA4u6M9CZwdtEP9+vUld+7colOuvVOZMmWkYcOGMm7cOJ+5Hj9+XAoUKCD9+vUzU7M9afPmzVK6dGmZMGGCtG3bNvXnf/zxh1x55ZXyySefmJHsIUOGRHXgPOWnP6TzxOWm/muHNJHzcvmeuu6gyTgFAQQQQAABBBBAAAErBQic3dFsBM4O2qFIkSLSpk0b0dFg76SjyTqNe968eT5zXbNmjVSqVEkmTZokLVq0SHNM/vz5pVu3bjJ48ODUn999992iU7U1cB4wYEDUB84/bt4jd/7ne1P/uU83kFLx5ztoHU5BAAEEEEAAAQQQQCB6BAic3dGWBM4O2kE3A9PNvTSY9U7t27eX5cuXy+rVq33m6pnOrRuK6ai1dypZsqQ0b95cxo4da36so9kaXGuwXapUqZAC571794r+8aRt27ZJ3bp1ZdOmTWZk263pz31HpOaz35riTXyohtS8IvBGa26tC+VCAAEEEEAAAQQQQCAzBAicM0Mx/DwInB0YauCsU6379++f5ux27dqZtcv+Amedbl2nTh2ZM2eO1KtXL825ulZaA2UNnI8dO2Y2H7vvvvtSp3SHMuKsx+qa6fTJ7YHzqdMpUr7PVNH/vnDX1XLndSUdtA6nIIAAAggggAACCCAQPQIEzu5oSwJnB+0Q6anaugnYK6+8IosXL5bzzjvPlFB33B45cqTs3r3b/Cxfvnx+S27riLNWqPbwb2X73iPyVKPy8vhN5Ry0DqcggAACCCCAAAIIIBA9AgTO7mhLAmcH7aDTrHXUecaMGWnODnZzMB2p1qnenpR+c7D7779f3n77bb8l69Chg4wfPz7oktv0sN316kJZ8vs/0uaGUvLsHYlB15EDEUAAAQQQQAABBBCIRgGb+vLR6O+pE4Gzg9bVkV+dqq1Tn4sXL25yWLRokdSsWTPg66iaNWtmXkela6E9r6PS0WQNpj2vo/r111/Ne5u901tvvSXvvvuuzJo1y7wvukKFCkGX3KaHLfmD5fL5ij+kXvlC8vaDNwRdRw5EAAEEEEAAAQQQQCAaBWzqy0ejP4FzGK2qO2frGuTChQubTbuOHDki3bt3l6JFi5rXRsXFxZncPWuNvdcW6/RrXefcunVr0ZHjVatWSY8ePaRz585mOra/FMoa5/R52PSwPTftV/nPnA1SrvAFMrNb2nXgYTQZpyKAAAIIIIAAAgggYKWATX15K4GDLDQjzkFCpT9sw4YNkpycbDb60nc6JyUlyejRoyU+/uxO0L4CZ81Hd8zu2bOnCZoTEhLkoYcekj59+kjOnP7fWxwrgfO7izZL38mrJH+enLJqYOPULyEcNhOnIYAAAggggAACCCBgtQCBszuaj8DZHe0Q0VLY9LDNWvOXdHh7qfH4qV8jKXh+7ojakDkCCCCAAAIIIIAAAm4WsKkv72bHcMtG4ByuoAXn2/Swrflzv9z64jyjOjW5rlxZ7EILhCkiAggggAACCCCAAAKREbCpLx8ZAXfkSuDsjnaIaClsetj2HTkhVw88s1v5f++rJjdfWSSiNmSOAAIIIIAAAggggICbBWzqy7vZMdyyETiHK2jB+TY9bCkpKZI4YIYcPHZSBjevLPfWLG2BMEVEAAEEEEAAAQQQQCAyAjb15SMj4I5cCZzd0Q4RLYVtD1uj0d/Jb38dlEfqXSHP3FoxojZkjgACCCCAAAIIIICAmwVs68u72TKcshE4h6Nnybm2PWz3vbFYvvttl9x+dXF5qc21lihTTAQQQAABBBBAAAEEMl/Atr585gu4I0cCZ3e0Q0RLYdvD1vOzlTJx8Ra5vvTF8vEjtSJqQ+YIIIAAAggggAACCLhZwLa+vJstwykbgXM4epaca9vD9vK362TkjN+kxEX5ZMEzN1miTDERQAABBBBAAAEEEMh8Adv68pkv4I4cCZzd0Q4RLYVtD9tny7ZJt49+kpw54mTt4CaSK2eOiPqQOQIIIIAAAggggAACbhWwrS/vVsdwy0XgHK6gBefb9rAt2vi33DNukZFd+MxNUvyifBYoU0QEEEAAAQQQQAABBDJfwLa+fOYLuCNHAmd3tENES2Hbw7Z1z2Gp+/xsY/LJIzWlWulLIupD5ggggAACCCCAAAIIuFXAtr68Wx3DLReBc7iCFpxv28N2/ORpqdB3qqSkiLx4zzXS/JoSFihTRAQQQAABBBBAAAEEMl/Atr585gu4I0cCZ3e0Q0RLYePDdsPQb2TngWPmPc76PmcSAggggAACCCCAAAKxKGBjXz4a24nAORpbNV2dbHzYWoxdICu27pX/q3mZDGp+VQy0ElVEAAEEEEAAAQQQQOBcARv78tHYjgTO0diqURA4d5qwTL5a+afccmVhGX/f9THQSlQRAQQQQAABBBBAAAECZ7feAwTObm2ZTCyXjd9SDf3qF3l93ia5stiFMjW5biZqkBUCCCCAAAIIIIAAAvYI2NiXt0c3+JISOAdvZe2RNj5sb8zfJIO+/EUK5sstP/VvZK09BUcAAQQQQAABBBBAIBwBG/vy4dTXrecSOLu1ZTKxXDY+bNNW7ZBH3vvRKKwe2Fjyn5crE0XICgEEEEAAAQQQQAABOwRs7MvbIRtaKQmcQ/Oy8mgbH7aV2/ZJ0svzjfc33W6UsoULWGlPoRFAAAEEEEAAAQQQCEfAxr58OPV167kEzm5tmUwsl40P298Hj8l1Q74xCm8/eIPUK18oE0XICgEEEEAAAQQQQAABOwRs7MvbIRtaKQmcQ/Oy8mgbH7aUlBSp2HeaHDt5Wp69I1Ha3FDKSnsKjQACCCCAAAIIIIBAOAI29uXDqa9bzyVwdmvLZGK5bH3Ybho5RzbuPiRP3FRWnmxUIRNFyAoBBBBAAAEEEEAAATsEbO3L26EbfCkJnIO3svZIWx+2duMXyYL1f8sdVUvIqNbXWOtPwRFAAAEEEEAAAQQQcCpga1/eaX3deh6Bs1tbJhPLZevD9vTHP8nHP26TmpfHy8SHa2SiCFkhgAACCCCAAAIIIGCHgK19eTt0gy8lgXPwVtYeaevDNnrmb/LirHVyWfz58t3TDaz1p+AIIIAAAggggAACCDgVsLUv77S+bj2PwNlhy2zcuFGSk5Nl9uzZkidPHklKSpJRo0ZJfHx8wBxnzpwpvXr1klWrVkmhQoWkY8eO0rt3b8mZM6c5d//+/TJ69GiZNm2arF27VuLi4iQxMVH69esnN910U8D80x9g68P20ZKt0v3TnyVPzhzy6+AmkiNHXMh15wQEEEAAAQQQQAABBGwWsLUvb7O5r7ITODtoUQ1sNZDVoHfgwIFy6NAh6dGjhxQrVkwWLFhgAl1/acmSJVK7dm1p1aqVCZg1eNZzNQgfPny4OU1/1rBhQ3nwwQelbt26ojtMjxs3Tj7//HPzR4P0UJKtD9v8dbul/X9/MFVd3PtmKVwgbyjV5lgEEEAAAQQQQAABBKwXsLUvbz18ugoQODto0REjRkifPn1ER51LlChhcli4cKEJiKdMmZJhYNu0aVPZunWrrFixQnLkyGHOHTZsmAnAt2/fLgkJCSYQ1+D7/PPPTy3dqVOn5OqrrzbBuo5yh5Jsfdg27DooN7/wnanq5E615ZpLLwql2hyLAAIIIIAAAggggID1Arb25a2HJ3AOvwnr168vuXPnFp1y7Z3KlCljRop1dNhXOn78uBQoUMBMudap2Z60efNmKV26tEyYMEHatm3rt4Dt2rWTpUuXmunboSRbH7Yjx0/Jlf2mmar+p11VuTWxWCjV5lgEEEAAAQQQQAABBKwXsLUvbz08gXP4TVikSBFp06aNjBkzJk1mOpqs07jnzZvn8yJr1qyRSpUqyaRJk6RFixZpjsmfP79069ZNBg8e7PPckydPSvny5aVKlSoyefLkkCph88NWdfBM2XPouPRpeqV0rHt5SPXmYAQQQAABBBBAAAEEbBewuS9vu713+Zmq7aA1dTMw3dxrwIABac5u3769LF++XFavXu0zV890bp1qraPW3qlkyZLSvHlzGTt2rM9zhw4dKn379pXvvvvOrHvOKO3du1f0jydt27bNnLNp0yYzsm1TavbvebJq+355sHYZ6ZdUyaaiU1YEEEAAAQQQQAABBMIWIHAOmzBTMiBwdsCogbNOte7fv3+as3Uqta5d9hc468ZhderUkTlz5ki9evXSnKtrpXUU2lfg/MUXX5jf6SZiuh46UNKAXtdMp082Bs4Pv7NUZvzylzSpXFRevfe6QFXn9wgggAACCCCAAAIIRJUAgbM7mpPA2UE7ZOVUbZ323bhxY7ML99tvv53hjt2eqkTTiPOAKavlrYW/S5WSBWXK43UctBanIIAAAggggAACCCBgrwCBszvajsDZQTvoNGsddZ4xY0aas4PdHExHqnWqtyf52xxMp33rtW688UazLjpXrlwOSiti88M2bu4GGfb1r5JwQR5Z2qeho/pzEgIIIIAAAggggAACtgrY3Je31dxXuQmcHbTmyJEjzVRtnfpcvHhxk8OiRYukZs2aAV9H1axZM/M6Kg2KPa+j0vc3azDteR2V5qc7Z+u65IoVK8r06dMlX758Dkp65hSbH7Yvf/5DHn9/uanHr4ObSN7cOR07cCICCCCAAAIIIIAAArYJ2NyXt806o/ISODtoTd05OzExUQoXLmw2CDty5Ih0795dihYtKrqOWd/BrMmz1th7bfHixYvNOufWrVtLhw4dZNWqVWbtcufOnUUDaE07d+6U66+/Xg4fPizvvfeeFCxYME0pa9SoEVKpbX7Ylm35R+54ZaGp75yn6kvphPwh1Z2DEUAAAQQQQAABBBCwWcDmvrzN7unLTuDssDU3bNggycnJZqMvfadzUlKSjB49WuLj41Nz9BU46y/1/c89e/Y0QXNCQoI89NBD0qdPH8mZ88xoqubZoEEDvyVLSUkJqdQ2P2x/7T8q1YfNMvV9v2N1qVU2IaS6czACCCCAAAIIIIAAAjYL2NyXt9mdwDmaWi/Iutj8sJ0+nSIV+k6VE6dSZESrKnJXtUuDrDWHIYAAAggggAACCCBgv4DNfXn79c/WgBHnaGpNP3Wx/WGr89y3su2fI9L1lvKSfEu5GGgxqogAAggggAACCCCAwBkB2/vy0dKOBM7R0pIZ1MP2h631a9/L4k175J7rL5Xhd1aJgRajiggggAACCCCAAAIIEDi76R4gcHZTa0SoLLYHzl0/XCGTlm+XuuUS5N0O1SOkRLYIIIAAAggggAACCLhPwPa+vPtEnZWIwNmZm1Vn2f6wjZj+q4ydvUGuKJRfZj1Z3yp7CosAAggggAACCCCAQDgCtvflw6m7m84lcHZTa0SoLLY/bBN+2Cy9J62SfLlzyi+DGqe+7itCXGSLAAIIIIAAAggggIBrBGzvy7sGMsyCEDiHCWjD6bY/bLPX7pQH3lxiqJf3bSgX589jAztlRAABBBBAAAEEEEAgbAHb+/JhA7gkAwJnlzREJIth+8O2dscBaTxmriH6qnMdqVy8YCS5yBsBBBBAAAEEEEAAAdcI2N6Xdw1kmAUhcA4T0IbTbX/YDhw9IYkDZhjq1/+vmjSsVMQGdsqIAAIIIIAAAggggEDYArb35cMGcEkGBM4uaYhIFiMaHrbEAdPlwNGTMvD2ynJfrdKR5CJvBBBAAAEEEEAAAQRcIxANfXnXYIZREALnMPBsOTUaHrYmY+bKrzsOyL9uvFx63nalLfSUEwEEEEAAAQQQQACBsASioS8fFoBLTiZwdklDRLIY0fCwPfjWEvn2153SrEoxeblt1UhykTcCCCCAAAIIIIAAAq4RiIa+vGswwygIgXMYeLacGg0PW+9JK2XCD1ukaqmL5LPHattCTzkRQAABBBBAAAEEEAhLIBr68mEBuORkAmeXNEQkixEND9vY2etlxPS1UqxgXvm+582R5CJvBBBAAAEEEEAAAQRcIxANfXnXYIZREALnMPBsOTUaHrbJy7dLlw9XSI44kbVDbpXcOXPYwk85EUAAAQQQQAABBBBwLBANfXnHlXfRiQTOLmqMSBUlGh62xZv2SOvXvjdE83s0kJIXnx8pLvJFAAEEEEAAAQQQQMA1AtHQl3cNZhgFIXAOA8+WU6PhYdv2z2Gp89xsQ/7Rv2rKDWUusYWfciKAAAIIIIAAAggg4FggGvryjivvohMJnF3UGJEqSjQ8bCdOnZYKfabK6RSRMXdfIy2uLREpLvJFAAEEEEAAAQQQQMA1AtHQl3cNZhgFIXAOA8+WU6PlYasxbJbs2H9UujepII/VL2sLP+VEAAEEEEAAAQQQQMCxQLT05R0DuOREAmeXNEQkixEtD9sdryyQZVv2SvsapWRIi8RIkpE3AggggAACCCCAAAKuEIiWvrwrMMMoBIFzGHi2nBotD9vj7y+TL3/+U26qWFjeuP96W/gpJwIIIIAAAggggAACjgWipS/vGMAlJxI4u6QhIlmMaHnYnv16jbw2d6NULFpApnW5MZJk5I0AAggggAACCCCAgCsEoqUv7wrMMApB4BwGni2nRsvD9vbC36X/lNVSIG8uWTmgsS38lBMBBBBAAAEEEEAAAccC0dKXdwzgkhMJnF3SEJEsRrQ8bDNW75CH3/3RUK0c0EgK5M0dSTbyRgABBBBAAAEEEEAg2wWipS+f7ZBhFoDAOUxAG06Plodt1fZ90uzf8w35jK43SvkiBWzgp4wIIIAAAggggAACCDgWiJa+vGMAl5xI4OywITZu3CjJyckye/ZsyZMnjyQlJcmoUaMkPj4+YI4zZ86UXr16yapVq6RQoULSsWNH6d27t+TMmTPNuRMnTpShQ4fK+vXr5dJLL5WuXbvKY489FjD/9AdEy8P2z6Hjcu3gmaZ6bz5wvTSoUDhkC05AAAEEEEAAAQQQQMAmgWjpy9tk7qusBM4OWnD//v2SmJhogt6BAwfKoUOHpEePHlKsWDFZsGCBxMXF+c11yZIlUrt2bWnVqpUJmDV41nM1CB8+fHjqeZMnT5aWLVuanzdv3lzmzp0rgwYNkrFjx8ojjzwSUqmj5WFLSUmRSv2my5ETp2Roy6ukXfXLQnLgYAQQQAABBBBAAAEEbBOIlr68be7py0vg7KAFR4wYIX369BEddS5RooTJYeHChSYgnjJlihl99peaNm0qW7dulRUrVkiOHDnMYcOGDTMB+Pbt2yUhIcH8rHLlylK6dGn56quvUrN6+OGH5fPPPzfH5cqVK+iSR9PDdvMLc2TDrkPSqcEV8nTjikEbcCACCCCAAAIIIIAAAjYKRFNf3kZ/T5kJnB20Xv369SV37tyiU669U5kyZaRhw4Yybtw4n7keP35cChQoIP369TNTsz1p8+bNJkieMGGCtG3bVjwPx3vvvSft2rVLPe67774TvbaOateqVSvokkfTw3bvf3+Qeet2S8trS8jou68J2oADEUAAAQQQQAABBBCwUSCa+vI2+hM4h9FqRYoUkTZt2siYMWPS5KKjyTqNe968eT5zX7NmjVSqVEkmTZokLVq0SHNM/vz5pVu3bjJ48GCZOnWq3HbbbbJ8+XK55pqzweGuXbukcOHCMn78eOnQoUPQNXDFw3bsoMgXnUXicpz5I3Fn/64z28/5mdfvU4+Nk+/W7ZY1Ow5J/vNySZmE/MYgzvzeB0dcjrM/Nr8/e1Dq3zKYVh80cGbk4alH0Bf1f2CKT4wQM/a/2iCkjDIpm7PXTEnxur7339PfAml/d26hz5bMby5e7ZoppqmFOHvFuAzqk/ohLf7rfLZe3vXx+TCYQ1PS3KtnjsuMusWllvFMWc/UK72s5/9T/vf7M1dP+2SmbanUsv2v3Gf+31Pus0JnMtFS+Kq7P++z1w/ppj7n4LTXTGucUe1CvWqmP02hFiCqjw/0iZFVlQ+uld1S2sxWCa726T8lfJXi7GeSszIG+7mYep3Uz3Kvz5t0n/nnHpuubGk+585+dvjKUT/vMuvzOzShwG3klrszcEk9NQ9c4jxFK8p1TTuGRpXJR7uiL5/JdbIxO0acHbSabgamm3sNGDAgzdnt27c3we7q1at95uqZzq0biunIsXcqWbKkWcusa5jff/99M9K8adMmMxLtSSdPnjQj3c8//7w8/fTTfku+d+9e0T+etG3bNqlbt+45+TmouvNTDu8Reb6M8/M5EwEEEEAAAQQQQACBLBZYlr+uVH36yyy+atrLEThnK3/qxQmcHbSDBs461bp///5pztZgV9cu+wucdYp1nTp1ZM6cOVKvXr005+paaR2F1sBZp2xrEK4PyWWXnd0AK9jAWQN6XTOdPqUPxB1U3fkpR/eLfPbwmRGmlNP/++P1d/Nzz5///d7HsSdOnZIdew/LyVMp/xur8jVi5ePbwzQje2eqEe430mdyCfxNZTBowX8zGii3zClPoKtk1e+1jdJ/85/xOHOgkde07Z72HvD5vX6a+0RHUs8dUQxdw99ohvfP/f09o6t56uNdL1/3eepxPp6L0GvzvyfBxwiIpw7p/3vmyUk7YuLR97TgOaPYXs9shr/z0UYZjR4F65yRoz+zzPmM8YzgO20ZzotGgcz4HArkklmfd4GuY/49DuOzyJ9FsKPG6csXzHPrbXP2s8yT07n/DmV0jHdfIv3nX/rPujN9l7R9mKxqp3DaKJh7IDuPCfQ8/RlfU6p3+m92FjF1GWe29uWzVcAdFydwdtAObp+q7coRZwfOnIIAAggggAACCCCAQKwLMOLsjjuAwNlBO+g0ax11njFjRpqzg90cTEeqdaq3J/nbHMyzWZjnODYHc9BYnIIAAggggAACCCCAgMUCBM7uaDwCZwftMHLkSDNVW6dLFC9e3OSwaNEiqVmzZsDXUTVr1sy8jkrXQnteR6Xvb9Zg2vt1VFdddZVoIP7FF1+kllDf36wbi8Xy66gcNBenIIAAAggggAACCCBgrQCBszuajsDZQTvoztmJiYlmh2tdT3zkyBHp3r27FC1a1LwqKu5/a/088i+ojQAADUZJREFUa4291yMsXrzYrHNu3bq12Rl71apV0qNHD+ncubNoAO1JGiDfcccd0rVrV7n99ttl7ty5Zt2yroHWADqUxMMWihbHIoAAAggggAACCCDgHgH68u5oCwJnh+2wYcMGSU5ONht96U7XSUlJMnr0aImPj0/N0VfgrL/U9z/37NnTBM0JCQny0EMPSZ8+fSRnzpxpSqO7aw8dOlTWr18vl156qQmiO3XqFHKJedhCJuMEBBBAAAEEEEAAAQRcIUBf3hXNoBsZhrGVoTvqQCkCCGjgXa5cOfN+aX3tFQkBBBBAAAEEEEAAAQTsEPC8WnbdunVStmxZOwodhaUkcI7CRk1fpfnz55v3OJMQQAABBBBAAAEEEEDATgEdBNMln6TsESBwzh73LL3q0aNHZenSpWYNdq5cubL02t4X83xbxsh3ZJoA38i4enLFF9/ICkQ2d+5ffCMrENncuX/xjaxAZHPPjPv35MmTsmPHDqlWrZrkzZs3sgUmd78CBM7cHFkmwPqMyFLji29kBSKbO/cvvpEViGzu3L/4RlYgsrlz/+IbWYHoyZ3AOXra0vU14YM5sk2EL76RFYhs7ty/+EZWILK5c//iG1mByObO/YtvZAWiJ3cC5+hpS9fXhA/myDYRvvhGViCyuXP/4htZgcjmzv2Lb2QFIps79y++kRWIntwJnKOnLV1fk71798qYMWOkS5cuctFFF7m+vLYVEN/Ithi++EZWILK5c//iG1mByObO/YtvZAUimzv3b2R9szJ3Aues1OZaCCCAAAIIIIAAAggggAAC1gkQOFvXZBQYAQQQQAABBBBAAAEEEEAgKwUInLNSm2shgAACCCCAAAIIIIAAAghYJ0DgbF2TUWAEEEAAAQQQQAABBBBAAIGsFCBwzkptroUAAggggAACCCCAAAIIIGCdAIGzdU1mX4E3btwoycnJMnv2bMmTJ48kJSXJqFGjJD4+3r7KuKzEc+bMkQYNGpxTquuuu06WLl3qstK6vzjbtm2T4cOHy+LFi+Wnn36S48ePS0pKyjkF37Vrl3Tt2lW++uorOXnypNx8883y4osvymWXXeb+SmZjCYPx9bwWJX0x9fNi9+7d2Vh6d1/6k08+kQkTJsiPP/5onEqXLi333nuvdOvWTc4777zUwvN57Kwdg/Hl89iZrZ41ffp0efbZZ+WXX36Rffv2SdGiRaVhw4YyYMAAKVmyZGrGy5YtM/e0fkYXKFBA2rRpY87Lly+f84vHwJnB+L711lvywAMPnKNx5513it7/pOAFtF9QtWpVWblypbz77rvSvn177uHg+Vx9JIGzq5vH/sLt379fEhMTpVChQjJw4EA5dOiQ9OjRQ4oVKyYLFiyQuLg4+yuZjTXwdNRee+01qVKlSmpJLrjgArnqqquysWR2Xlo977nnHrn++utFXx8xf/78cwLnU6dOSfXq1eWff/6R5557zgQl/fr1E73X9R/J888/387KZ0Gpg/H1BM7aYW7cuHFqqXLnzi36hRDJt0CNGjVMsNyiRQsTdHz//fcyePBgadq0qXz88cfmJD6Pnd89wfjyeezcd+LEibJ8+XJRZ/2SbN26dTJo0CDJkSOHCab1c3Xz5s1y9dVXyw033CBPP/20bN++XZ588kkTYH/wwQfOLx4DZwbj6wmcp0yZYvpsnqTtUa5cuRhQyrwqvvDCCzJy5EjZsWNHmsCZezjzjLMrJwLn7JKPkeuOGDFC+vTpIzrKUaJECVPrhQsXSu3atUU/nHX0meRcwNNRmzdvntSpU8d5RpxpBE6fPm06apqGDBkiffv2PSdw1iCkdevWZsRDA2xNW7ZskSuuuMLMpHjiiSfQ9CMQjK8ncE7/LT2oGQvoLAjvzq4erbMnevbsKWqqsyH4PHZ+FwXjy+exc19fZ86YMcN8efbll1+aL4A6depkRj61P5E/f35zyvvvvy/t2rUzM4S8vzzO3JJEZ27pfT2B89atW9OM8kdn7SNXK/1C58orr5SXX35Z7rvvvjSBM/dw5NyzKmcC56ySjtHr1K9fX3SkaObMmWkEypQpY74lHjduXIzKZE616ahljqOvXPwFzvfff7+ZLaEjIt5Jp8zrva6dEVJgAX++BM6B7YI9Qj93GzVqZL6srFmzpvB5HKxccMel9+XzODi3YI/SZQfVqlWTadOmmQBaZ1Rov+H1119PzeLYsWNSsGBBM+unV69ewWbNcSJmWYe3L4Fz5twWrVq1krx585ov37Wv6/0lMPdw5hhnZy4EztmpHwPXLlKkiFmDNGbMmDS11W+PddqgjpSSnAt4OmqFCxc26xoTEhKkefPmZqTpkksucZ4xZ/odcdZp2rrUYPLkyWmU9JtknUWh39aTAgsECpz1Xtbp8BdeeKEJ/nRaPGvIA7t6H6HBxLBhw8x0QfXk8zg0v0BHp/fl8ziQWODf61IY/bN+/Xp5/PHHZc+ePbJkyRI5ceKEGWUePXq0dOnSJU1GlStXNutJNUAhZSzgz1e/9PUEzvo5oTMsihcvbvpvusyONeTB3Vn6JY/OSFu7dq3olzregfPhw4e5h4NjdPVRBM6ubh77C6ebgem3wLpe0TvpRgm6nmn16tX2VzIba6CGOlWtXr16ouuadV2jbpSi32pqZ8N7U6BsLKaVl/YX2JUvX15q1aplOhneSZckaKdO1/GTAgv48/3zzz/N2lwNlvXLH52COXToUMmZM6f5uwaApMAC2nHT0SRds+8ZoePzOLBbsEf48uXzOFg9/8dVrFjRBB2a9P794osvzJr9P/74wyz3evPNN0Vn/XgnXaako866WSMpYwF/vnqWbiC2aNEis4ZcA+lZs2aZ5Uc6U0V/R8pY4OjRo2ZvmUcffdSsvU8/e4p7ODruIALn6GhH19ZCO2q9e/eW/v37pymjrklasWIFgXMEWk47Grfffru88847ZlddkjMBf4GdbpKiHTXtwHknvc91ZgWBc3De/nx9na2fFdqJ1s8RXXdOylhAR+n0yx3dfPGHH34wo/aa+DzOnDvHn6+v3Pk8Ds1cv0w/cOCACZ71S+BcuXKZpTEHDx406271C0tdN+qddM+Uiy66iMA5CGp/vvrFg6/073//Wzp37ixz586VunXrBnGF2D1EZ6DoGnz9gle/eEgfOOvaZ+5h++8PAmf729DVNWBqYNY3j74+SV/T0aFDB/OKJJIzAX+BHVO1nXmmPyuUwFnPrVSpktnZ9fPPP8+cAkRpLvrFjb4eTV/9pWubS5UqlVpTPo/Db/SMfH3lzuexc3Nd9qKzp3TpkS6FYaq2c0tfZ3r76i7lvtLOnTvNEg8dedZXMJJ8C+hu2RUqVDCvBNTPX026aajuAq9vPbn77rtNMM09bP8dROBsfxu6ugY6xUdHOdJvmMTmYJFrNk9HrWPHjuesLY/cVaMv54w2B9OA5LfffktTaTYHC+0ecBI46zT59GvLQ7tqdB+ta+qaNWsm+q5b3T9Cv2zwTnweh9f+gXwzCpz5PHZmr9O09RVrr776qgmidQmH96aibA7mzNVzlrevr5x0rbPuoeJrbXl4V46us/29w91TS11qpO925h62v90JnO1vQ1fXQN9jp1NYN23aZDaa0KRraHSHV15HFZmm0xE57Wi899575jUdJGcC/gI7nYp11113ydKlS1PfK6zf3F9++eW8jioE6lACZw0Edd2dblKjnyekcwV00x+9L/VLSl2bqDMj0ic+j53fOcH4+sqdz2Pn5vrlpI7iPf/88+a9zbpZmOd1VPpeZ036/mbdwIrXUYXunN7XVw46a003Y5s/f755jSjJt8DevXvN8kPvpJsy6r2p+/zoFz66Fw33sP13EIGz/W3o6hroztmJiYnmG0vdIOzIkSPSvXt3s9mHrlvSNXgk5wK6yZoGbLqjqGdzMO1k6JRW/YJCR/tJoQlox0zTp59+ajpl+t5mTfpNsa6z1Q60BnH79u0zOz3rBmy6tkn/f+XKleLp0IV21dg5OpCvbqqiSb9c083Bfv75Z7MztO7qqpsvsVu873vlkUceMVMCBw0aZF7Z4530HeP6jmc+j50/Z8H48nns3Ldly5bmi0h9F7P+W6ZrcfWLHp1BpQGJPvc6HVanvtaoUcNsvqSbLel/b7nlFvNZTfIvEIyvBnc33XST2eBKpxV/8803ZrmX/lzfpU0KTcDXqxW5h0MzdOPRBM5ubJUoK9OGDRskOTlZdCqLfhgnJSWZaT/x8fFRVtOsr45unqK7auuHsX4poRtP6D+QuomSv80+sr6Udl3R35c5uiGNZydtXfel6710F1cNpLWzoR0MDa5JGQsE8n3jjTfklVdeEf3c0A2BdH1dkyZNTEDombWC8bkCeu/p54Cv5L0TMZ/Hzu6eYHz5PHZmq2fpl5Affvihee51Squuzb/tttukR48e5ot3T9J3D3fr1k0WL15s9vLQET115wvLjO2D8dWR5alTp4puYqWv/9Ilder7zDPP8IYOB7e2r8BZs+EedoDpolMInF3UGBQFAQQQQAABBBBAAAEEEEDAfQL/Dx9noKRgfCPXAAAAAElFTkSuQmCC\" width=\"865.7777777777778\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "the_model = the_model('Mainz', 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predict('Mainz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last observed value is  534.0\n",
      "the prediction for  48  steps ahead is  [[[510.89203]]]\n"
     ]
    }
   ],
   "source": [
    "print('last observed value is ', prediction['last_observed_city_level'])\n",
    "print('the prediction for ', future_timesteps, ' steps ahead is ', prediction['the_prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
