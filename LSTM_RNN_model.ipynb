{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpickled_dataframe\n",
    "# contains Rhein river levels from 01/01/2000 to 31/12/2012\n",
    "\n",
    "df = pd.read_pickle(\"riverlevels.pandas.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455904, 15)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Andernach</th>\n",
       "      <th>Bingen</th>\n",
       "      <th>Bonn</th>\n",
       "      <th>Frankfurt Osthafen</th>\n",
       "      <th>Kalkofen Neu</th>\n",
       "      <th>Kaub</th>\n",
       "      <th>Koblenz</th>\n",
       "      <th>Koblenz Up</th>\n",
       "      <th>Mainz</th>\n",
       "      <th>Oberwinter</th>\n",
       "      <th>Oestrich</th>\n",
       "      <th>Raunheim</th>\n",
       "      <th>Rockenau Ska</th>\n",
       "      <th>Speyer</th>\n",
       "      <th>Worms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:00+00:00</th>\n",
       "      <td>617.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>652.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>459.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>522.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>557.0</td>\n",
       "      <td>345.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>426.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:15:00+00:00</th>\n",
       "      <td>616.0</td>\n",
       "      <td>373.0</td>\n",
       "      <td>651.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>515.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>345.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>425.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:30:00+00:00</th>\n",
       "      <td>615.0</td>\n",
       "      <td>373.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>314.0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>344.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>570.0</td>\n",
       "      <td>425.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:45:00+00:00</th>\n",
       "      <td>613.0</td>\n",
       "      <td>373.0</td>\n",
       "      <td>649.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>513.0</td>\n",
       "      <td>516.0</td>\n",
       "      <td>474.0</td>\n",
       "      <td>554.0</td>\n",
       "      <td>344.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>570.0</td>\n",
       "      <td>425.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 01:00:00+00:00</th>\n",
       "      <td>612.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>647.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>457.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>509.0</td>\n",
       "      <td>474.0</td>\n",
       "      <td>553.0</td>\n",
       "      <td>344.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>570.0</td>\n",
       "      <td>425.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Andernach  Bingen   Bonn  Frankfurt Osthafen  \\\n",
       "2000-01-01 00:00:00+00:00      617.0   374.0  652.0               200.0   \n",
       "2000-01-01 00:15:00+00:00      616.0   373.0  651.0               199.0   \n",
       "2000-01-01 00:30:00+00:00      615.0   373.0  650.0               198.0   \n",
       "2000-01-01 00:45:00+00:00      613.0   373.0  649.0               199.0   \n",
       "2000-01-01 01:00:00+00:00      612.0   372.0  647.0               200.0   \n",
       "\n",
       "                           Kalkofen Neu   Kaub  Koblenz  Koblenz Up  Mainz  \\\n",
       "2000-01-01 00:00:00+00:00         315.0  459.0    517.0       522.0  475.0   \n",
       "2000-01-01 00:15:00+00:00         315.0  458.0    515.0       520.0  475.0   \n",
       "2000-01-01 00:30:00+00:00         314.0  458.0    514.0       517.0  475.0   \n",
       "2000-01-01 00:45:00+00:00         312.0  458.0    513.0       516.0  474.0   \n",
       "2000-01-01 01:00:00+00:00         311.0  457.0    512.0       509.0  474.0   \n",
       "\n",
       "                           Oberwinter  Oestrich  Raunheim  Rockenau Ska  \\\n",
       "2000-01-01 00:00:00+00:00       557.0     345.0     182.0         296.0   \n",
       "2000-01-01 00:15:00+00:00       555.0     345.0     182.0         295.0   \n",
       "2000-01-01 00:30:00+00:00       555.0     344.0     180.0         296.0   \n",
       "2000-01-01 00:45:00+00:00       554.0     344.0     179.0         296.0   \n",
       "2000-01-01 01:00:00+00:00       553.0     344.0     178.0         294.0   \n",
       "\n",
       "                           Speyer  Worms  \n",
       "2000-01-01 00:00:00+00:00   571.0  426.0  \n",
       "2000-01-01 00:15:00+00:00   571.0  425.0  \n",
       "2000-01-01 00:30:00+00:00   570.0  425.0  \n",
       "2000-01-01 00:45:00+00:00   570.0  425.0  \n",
       "2000-01-01 01:00:00+00:00   570.0  425.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Andernach</th>\n",
       "      <th>Bingen</th>\n",
       "      <th>Bonn</th>\n",
       "      <th>Frankfurt Osthafen</th>\n",
       "      <th>Kalkofen Neu</th>\n",
       "      <th>Kaub</th>\n",
       "      <th>Koblenz</th>\n",
       "      <th>Koblenz Up</th>\n",
       "      <th>Mainz</th>\n",
       "      <th>Oberwinter</th>\n",
       "      <th>Oestrich</th>\n",
       "      <th>Raunheim</th>\n",
       "      <th>Rockenau Ska</th>\n",
       "      <th>Speyer</th>\n",
       "      <th>Worms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-12-31 22:45:00+00:00</th>\n",
       "      <td>640.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>338.0</td>\n",
       "      <td>538.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>516.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>573.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>472.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-31 23:00:00+00:00</th>\n",
       "      <td>640.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>338.0</td>\n",
       "      <td>537.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>516.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>573.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>471.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-31 23:15:00+00:00</th>\n",
       "      <td>639.0</td>\n",
       "      <td>428.0</td>\n",
       "      <td>669.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>537.0</td>\n",
       "      <td>548.0</td>\n",
       "      <td>515.0</td>\n",
       "      <td>534.0</td>\n",
       "      <td>572.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>471.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-31 23:30:00+00:00</th>\n",
       "      <td>639.0</td>\n",
       "      <td>428.0</td>\n",
       "      <td>669.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>536.0</td>\n",
       "      <td>547.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>534.0</td>\n",
       "      <td>572.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>607.0</td>\n",
       "      <td>471.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-31 23:45:00+00:00</th>\n",
       "      <td>638.0</td>\n",
       "      <td>428.0</td>\n",
       "      <td>668.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>536.0</td>\n",
       "      <td>545.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>534.0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>404.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>607.0</td>\n",
       "      <td>470.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Andernach  Bingen   Bonn  Frankfurt Osthafen  \\\n",
       "2012-12-31 22:45:00+00:00      640.0   430.0  670.0               266.0   \n",
       "2012-12-31 23:00:00+00:00      640.0   430.0  670.0               266.0   \n",
       "2012-12-31 23:15:00+00:00      639.0   428.0  669.0               265.0   \n",
       "2012-12-31 23:30:00+00:00      639.0   428.0  669.0               265.0   \n",
       "2012-12-31 23:45:00+00:00      638.0   428.0  668.0               265.0   \n",
       "\n",
       "                           Kalkofen Neu   Kaub  Koblenz  Koblenz Up  Mainz  \\\n",
       "2012-12-31 22:45:00+00:00         338.0  538.0    549.0       516.0  535.0   \n",
       "2012-12-31 23:00:00+00:00         338.0  537.0    549.0       516.0  535.0   \n",
       "2012-12-31 23:15:00+00:00         337.0  537.0    548.0       515.0  534.0   \n",
       "2012-12-31 23:30:00+00:00         337.0  536.0    547.0       511.0  534.0   \n",
       "2012-12-31 23:45:00+00:00         336.0  536.0    545.0       511.0  534.0   \n",
       "\n",
       "                           Oberwinter  Oestrich  Raunheim  Rockenau Ska  \\\n",
       "2012-12-31 22:45:00+00:00       573.0     406.0     258.0         303.0   \n",
       "2012-12-31 23:00:00+00:00       573.0     405.0     258.0         303.0   \n",
       "2012-12-31 23:15:00+00:00       572.0     405.0     258.0         303.0   \n",
       "2012-12-31 23:30:00+00:00       572.0     405.0     257.0         303.0   \n",
       "2012-12-31 23:45:00+00:00       571.0     404.0     257.0         303.0   \n",
       "\n",
       "                           Speyer  Worms  \n",
       "2012-12-31 22:45:00+00:00   608.0  472.0  \n",
       "2012-12-31 23:00:00+00:00   608.0  471.0  \n",
       "2012-12-31 23:15:00+00:00   608.0  471.0  \n",
       "2012-12-31 23:30:00+00:00   607.0  471.0  \n",
       "2012-12-31 23:45:00+00:00   607.0  470.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task : predict future river levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Are there any \"nan\" values in the dataset ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Andernach</th>\n",
       "      <th>Bingen</th>\n",
       "      <th>Bonn</th>\n",
       "      <th>Frankfurt Osthafen</th>\n",
       "      <th>Kalkofen Neu</th>\n",
       "      <th>Kaub</th>\n",
       "      <th>Koblenz</th>\n",
       "      <th>Koblenz Up</th>\n",
       "      <th>Mainz</th>\n",
       "      <th>Oberwinter</th>\n",
       "      <th>Oestrich</th>\n",
       "      <th>Raunheim</th>\n",
       "      <th>Rockenau Ska</th>\n",
       "      <th>Speyer</th>\n",
       "      <th>Worms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-03-31 23:00:00+00:00</th>\n",
       "      <td>394.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>357.0</td>\n",
       "      <td>347.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>368.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Andernach  Bingen   Bonn  Frankfurt Osthafen  \\\n",
       "2008-03-31 23:00:00+00:00      394.0   252.0  424.0               222.0   \n",
       "\n",
       "                           Kalkofen Neu   Kaub  Koblenz  Koblenz Up  Mainz  \\\n",
       "2008-03-31 23:00:00+00:00         331.0  289.0    325.0       329.0  357.0   \n",
       "\n",
       "                           Oberwinter  Oestrich  Raunheim  Rockenau Ska  \\\n",
       "2008-03-31 23:00:00+00:00       347.0     238.0     199.0         274.0   \n",
       "\n",
       "                           Speyer  Worms  \n",
       "2008-03-31 23:00:00+00:00   368.0    NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2008-03-31 23:00:00+00:00'], dtype='datetime64[ns, UTC]', freq='15T')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.isnull().any(axis=1)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "230.75"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace the nan value by the average values of the two preceding and the two following values\n",
    "df['Worms']['2008-03-31 23:00:00+00:00'] = (1/4) * ( df['Worms']['2008-03-31 22:30:00+00:00'] + \n",
    "                                                    df['Worms']['2008-03-31 22:45:00+00:00'] +\n",
    "                                                    df['Worms']['2008-03-31 23:15:00+00:00'] +\n",
    "                                                    df['Worms']['2008-03-31 23:30:00+00:00'] )\n",
    "\n",
    "df['Worms']['2008-03-31 23:00:00+00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value = df.values.max()\n",
    "min_value = df.values.min()\n",
    "values_range = max_value - min_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_set(target_city, future_timesteps) :\n",
    "    \n",
    "    \"\"\"\n",
    "    future_timesteps : the timesteps I want to predict in the future\n",
    "            for example, if I want to predict 1 hour in the future then the parameter should be 4,\n",
    "            since the dataset has 4 samples per hour\n",
    "    \"\"\"\n",
    "    \n",
    "    # consider all samples except for the last \"future_timesteps\"\n",
    "    X_data = df.values[0:-future_timesteps]\n",
    "    \n",
    "    # as target for each sample we will set the respective city value \"future_timesteps\" ahead\n",
    "    df_targets = df[target_city].shift(-future_timesteps) # we shift the target_city sequence by \"future_timesteps\" ahead\n",
    "    y_data = df_targets.values[:-future_timesteps]\n",
    "    \n",
    "    # normalize values \n",
    "    X_data = ( X_data - min_value ) / ( values_range )\n",
    "    y_data = ( y_data - min_value ) / ( values_range )\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size = 0.1, random_state = 0)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_timeseries (target_city) :\n",
    "    \n",
    "    target_city_levels = df[target_city]\n",
    "    l=np.arange(target_city_levels.size)\n",
    "    %matplotlib notebook\n",
    "    plt.plot(l,target_city_levels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def the_model (target_city, future_timesteps) :\n",
    "    \n",
    "    # PART 1 : TUNING HYPERPARAMETERS\n",
    "    \n",
    "    X_trainval, X_val, y_trainval, y_val = train_test_split( get_train_test_set(target_city, future_timesteps)[0] ,\n",
    "                                                            get_train_test_set(target_city, future_timesteps)[2],\n",
    "                                                            test_size = 0.1, random_state = 0)\n",
    "    \n",
    "    # fix dimensions to feed data into the lstm rnn\n",
    "    X_trainval = np.reshape(X_trainval, (X_trainval.shape[0],1,X_trainval.shape[1]))\n",
    "    X_val = np.reshape(X_val, (X_val.shape[0],1,X_val.shape[1]))\n",
    "    \n",
    "    best_val_loss = 1\n",
    "\n",
    "    for lstm_units in [128,64]:\n",
    "        for hidden_dense_layers in [0,1,2]:\n",
    "            for dense_units in [64,32,16]:\n",
    "                for act_fct in ['linear', 'tanh','sigmoid']:\n",
    "\n",
    "                    model = Sequential()\n",
    "                    # input layer\n",
    "                    model.add(LSTM(units = lstm_units, return_sequences=True, input_shape = (1,15) )) \n",
    "                    # hidden dense layers\n",
    "                    if hidden_dense_layers == 1:\n",
    "                        model.add(Dense(dense_units, activation = act_fct))\n",
    "                    if hidden_dense_layers == 2:\n",
    "                        model.add(Dense(dense_units, activation = act_fct))\n",
    "                        model.add(Dense(dense_units, activation = act_fct))\n",
    "                    # output layer\n",
    "                    model.add(Dense(1, activation = 'linear'))\n",
    "\n",
    "                    model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "                    h = model.fit(X_trainval, y_trainval,\n",
    "                                  epochs = 10, batch_size = 500,\n",
    "                                validation_data = (X_val, y_val))\n",
    "\n",
    "                    val_loss = h.history['val_loss'][-1]\n",
    "\n",
    "                    if val_loss < best_val_loss:\n",
    "                        best_val_loss = val_loss\n",
    "                        opt_parameters = {'lstm_units' : lstm_units,\n",
    "                                            'hidden_dense_layers' : hidden_dense_layers,\n",
    "                                            'dense_units' : dense_units,\n",
    "                                            'act_fct' : act_fct}\n",
    "    \n",
    "    \n",
    "    # PART 2 : THE FINAL/OPTIMAL MODEL\n",
    "    \n",
    "    model = Sequential()\n",
    "    # input layer\n",
    "    model.add(LSTM(units = opt_parameters['lstm_units'] , return_sequences=True, input_shape = (1,15) )) \n",
    "    # hidden dense layers\n",
    "    if opt_parameters['hidden_dense_layers'] == 1:\n",
    "        model.add(Dense(opt_parameters['dense_units'], activation = act_fct))\n",
    "    if opt_parameters['hidden_dense_layers'] == 2:\n",
    "        model.add(Dense(opt_parameters['dense_units'], activation = opt_parameters['act_fct']))\n",
    "        model.add(Dense(opt_parameters['dense_units'], activation = opt_parameters['act_fct']))\n",
    "    # output layer\n",
    "    model.add(Dense(1, activation = 'linear'))\n",
    "\n",
    "    model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "    \n",
    "    model.summary()\n",
    "\n",
    "    return opt_parameters, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that training the model depends on the y_data and consequently on the future time steps. This means that each time we want to make a different prediction we must train the model on different dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(target_city, future_timesteps) :\n",
    "    \n",
    "    a = the_model(target_city, future_timesteps)\n",
    "    \n",
    "    model = a[1]\n",
    "        \n",
    "    X_train = get_train_test_set(target_city, future_timesteps)[0]\n",
    "    X_test = get_train_test_set(target_city, future_timesteps)[1]\n",
    "    y_train = get_train_test_set(target_city, future_timesteps)[2]\n",
    "    y_test = get_train_test_set(target_city, future_timesteps)[3]\n",
    "\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0],1,X_train.shape[1]))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0],1,X_test.shape[1]))\n",
    "\n",
    "    h = model.fit(X_train, y_train,\n",
    "           epochs = 10, batch_size = 500,\n",
    "           validation_data = (X_test, y_test))\n",
    "\n",
    "    train_loss = h.history['loss'][-1]\n",
    "    test_loss = h.history['val_loss'][-1]\n",
    "    \n",
    "    # \n",
    "    most_recent_sample_point = df.values[-1]\n",
    "    column = df.columns.get_loc(target_city)\n",
    "    last_observed_city_level = most_recent_sample_point[column]\n",
    "    \n",
    "    # normalize\n",
    "    norm_most_recent_sample_point = (most_recent_sample_point - min_value) / ( values_range)\n",
    "    \n",
    "    # normalized prediction\n",
    "    norm_most_recent_sample_point = np.reshape(norm_most_recent_sample_point, (1,1,15))\n",
    "    norm_prediction = model.predict(norm_most_recent_sample_point)\n",
    "    \n",
    "    # un-normalized prediction\n",
    "    unnorm_prediction = norm_prediction * values_range + min_value\n",
    "    \n",
    "    all_results = {'optimal_parameters' : a[0],\n",
    "              'train_loss' : train_loss,\n",
    "              'test_loss' : test_loss,\n",
    "              'last_observed_city_level' : last_observed_city_level,\n",
    "               'the_prediction' : unnorm_prediction}\n",
    "    \n",
    "    return  all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we predict the river level in the city of Mainz 12 hours (48 timesteps) into the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"922.4\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# zoomed plot\n",
    "plot_timeseries('Mainz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 9s 24us/sample - loss: 0.0011 - val_loss: 7.8685e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 8s 23us/sample - loss: 5.8966e-05 - val_loss: 4.0065e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 8s 21us/sample - loss: 3.4373e-05 - val_loss: 3.1093e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 8s 22us/sample - loss: 2.9933e-05 - val_loss: 2.8679e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.8168e-05 - val_loss: 2.7487e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 7s 20us/sample - loss: 2.7134e-05 - val_loss: 2.7283e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.6309e-05 - val_loss: 2.5441e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.5531e-05 - val_loss: 2.4717e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 8s 22us/sample - loss: 2.5287e-05 - val_loss: 2.4605e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.4817e-05 - val_loss: 2.4977e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 0.0015 - val_loss: 8.0500e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 6.3173e-05 - val_loss: 4.8775e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 4.1016e-05 - val_loss: 3.5268e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 3.3209e-05 - val_loss: 3.1540e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 6s 15us/sample - loss: 3.0698e-05 - val_loss: 2.9978e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 2.9204e-05 - val_loss: 3.1417e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 2.8044e-05 - val_loss: 2.7241e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.7138e-05 - val_loss: 2.9999e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.6267e-05 - val_loss: 2.5191e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.5991e-05 - val_loss: 2.5063e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 7s 19us/sample - loss: 0.0014 - val_loss: 8.5207e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 6s 15us/sample - loss: 6.6507e-05 - val_loss: 4.9946e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 4.0219e-05 - val_loss: 3.3506e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 3.1825e-05 - val_loss: 3.0430e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 2.9775e-05 - val_loss: 3.0192e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 6s 15us/sample - loss: 2.8435e-05 - val_loss: 2.7761e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 2.7270e-05 - val_loss: 2.6547e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.6517e-05 - val_loss: 2.5328e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 7s 20us/sample - loss: 2.6006e-05 - val_loss: 2.8190e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.5563e-05 - val_loss: 2.7167e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 8s 21us/sample - loss: 0.0013 - val_loss: 8.6521e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 6.4710e-05 - val_loss: 4.6996e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 3.8794e-05 - val_loss: 3.3552e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 3.1998e-05 - val_loss: 3.0287e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 2.9877e-05 - val_loss: 2.8827e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.8645e-05 - val_loss: 2.7602e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.7687e-05 - val_loss: 2.6678e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 2.6768e-05 - val_loss: 2.9036e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 2.5915e-05 - val_loss: 2.5816e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 2.5731e-05 - val_loss: 2.7883e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 7s 19us/sample - loss: 0.0011 - val_loss: 6.1021e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 4.3821e-05 - val_loss: 3.3967e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 3.1284e-05 - val_loss: 3.0005e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 2.9262e-05 - val_loss: 2.8580e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 2.8110e-05 - val_loss: 2.7512e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 2.7097e-05 - val_loss: 2.6362e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 2.6248e-05 - val_loss: 2.5761e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 2.5831e-05 - val_loss: 2.5484e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 2.5203e-05 - val_loss: 2.4093e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 2.4795e-05 - val_loss: 2.7115e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 7s 20us/sample - loss: 9.8595e-04 - val_loss: 7.7620e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 5.6418e-05 - val_loss: 4.1161e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 3.5172e-05 - val_loss: 3.1402e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 3.0085e-05 - val_loss: 2.9621e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 2.8438e-05 - val_loss: 2.7684e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.7566e-05 - val_loss: 2.6633e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 2.6691e-05 - val_loss: 2.6039e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 2.6462e-05 - val_loss: 2.8130e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 2.5949e-05 - val_loss: 2.4593e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 2.5297e-05 - val_loss: 2.6422e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 7s 19us/sample - loss: 0.0015 - val_loss: 8.0978e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 6.3612e-05 - val_loss: 4.8695e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 3.9683e-05 - val_loss: 3.3638e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 3.1195e-05 - val_loss: 2.9597e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 2.9167e-05 - val_loss: 2.8286e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 2.7943e-05 - val_loss: 2.7964e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 2.6937e-05 - val_loss: 2.5971e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 2.5948e-05 - val_loss: 2.5822e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 2.5414e-05 - val_loss: 2.4452e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 2.4971e-05 - val_loss: 2.4240e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 7s 20us/sample - loss: 0.0013 - val_loss: 7.5099e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 4.9638e-05 - val_loss: 3.3574e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 3.1101e-05 - val_loss: 2.9062e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 2.8393e-05 - val_loss: 2.7298e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.7011e-05 - val_loss: 2.6286e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 8s 22us/sample - loss: 2.6046e-05 - val_loss: 2.5780e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.5392e-05 - val_loss: 2.4730e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.4850e-05 - val_loss: 2.4144e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.4598e-05 - val_loss: 2.4159e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.4520e-05 - val_loss: 2.3611e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 7s 19us/sample - loss: 0.0011 - val_loss: 7.9117e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 5.9757e-05 - val_loss: 4.4066e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 3.7022e-05 - val_loss: 3.2470e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 3.1056e-05 - val_loss: 2.9505e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 2.9230e-05 - val_loss: 3.1345e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.8053e-05 - val_loss: 2.7089e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.7136e-05 - val_loss: 2.6309e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 2.6331e-05 - val_loss: 2.6339e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 2.5574e-05 - val_loss: 2.5521e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 2.5348e-05 - val_loss: 2.4022e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 8s 21us/sample - loss: 6.0096e-04 - val_loss: 3.9170e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 3.3015e-05 - val_loss: 2.9887e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.9292e-05 - val_loss: 2.7554e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.7627e-05 - val_loss: 2.5802e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.6648e-05 - val_loss: 2.5160e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.6308e-05 - val_loss: 2.6340e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 6s 18us/sample - loss: 2.6789e-05 - val_loss: 3.2720e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.6419e-05 - val_loss: 2.4029e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.6394e-05 - val_loss: 2.3229e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.5797e-05 - val_loss: 2.3658e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 9s 23us/sample - loss: 8.1459e-04 - val_loss: 5.2928e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 3.8277e-05 - val_loss: 3.2236e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 3.1325e-05 - val_loss: 2.9442e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.9168e-05 - val_loss: 2.9332e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.8553e-05 - val_loss: 2.5985e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.8055e-05 - val_loss: 3.2896e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 7s 19us/sample - loss: 2.8005e-05 - val_loss: 2.8488e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.7261e-05 - val_loss: 2.8148e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.7228e-05 - val_loss: 3.2509e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.6112e-05 - val_loss: 2.4295e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 8s 21us/sample - loss: 0.0239 - val_loss: 1.6281e-04\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 9.1279e-05 - val_loss: 4.7865e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 3.8796e-05 - val_loss: 3.3652e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 3.1920e-05 - val_loss: 3.0228e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.9630e-05 - val_loss: 2.8998e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.8112e-05 - val_loss: 2.7413e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.7231e-05 - val_loss: 2.6330e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.6496e-05 - val_loss: 2.7026e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.5751e-05 - val_loss: 2.5751e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.5710e-05 - val_loss: 2.4449e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 8s 21us/sample - loss: 6.4910e-04 - val_loss: 4.3550e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 3.5046e-05 - val_loss: 3.0911e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 3.0393e-05 - val_loss: 2.8698e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.8643e-05 - val_loss: 2.7115e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.7413e-05 - val_loss: 2.5861e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.6692e-05 - val_loss: 2.5120e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.6472e-05 - val_loss: 2.6187e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.6024e-05 - val_loss: 2.7206e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 7s 19us/sample - loss: 2.5985e-05 - val_loss: 2.4303e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.5595e-05 - val_loss: 2.3461e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 8s 22us/sample - loss: 8.5549e-04 - val_loss: 5.1763e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 3.6982e-05 - val_loss: 3.1201e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 3.0643e-05 - val_loss: 2.8916e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.8736e-05 - val_loss: 2.8370e-05\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.7665e-05 - val_loss: 2.6473e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.7231e-05 - val_loss: 2.6539e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.7050e-05 - val_loss: 2.4799e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.6357e-05 - val_loss: 2.4073e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.6676e-05 - val_loss: 2.3928e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.5618e-05 - val_loss: 2.3977e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 8s 21us/sample - loss: 0.0187 - val_loss: 1.8354e-04\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 6s 18us/sample - loss: 9.3189e-05 - val_loss: 4.4035e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 3.7009e-05 - val_loss: 3.3440e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 3.1400e-05 - val_loss: 2.9899e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 6s 18us/sample - loss: 2.9276e-05 - val_loss: 2.8211e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.7888e-05 - val_loss: 2.8235e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.6875e-05 - val_loss: 2.7751e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.5809e-05 - val_loss: 2.5158e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.5211e-05 - val_loss: 2.4213e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 6s 18us/sample - loss: 2.4988e-05 - val_loss: 2.4963e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 7s 20us/sample - loss: 7.3491e-04 - val_loss: 5.3806e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 3.8325e-05 - val_loss: 3.0889e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.9069e-05 - val_loss: 2.7649e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.7516e-05 - val_loss: 2.6959e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.6635e-05 - val_loss: 2.6752e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 6s 18us/sample - loss: 2.6054e-05 - val_loss: 2.6067e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.6040e-05 - val_loss: 2.4175e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.5888e-05 - val_loss: 2.7981e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.5762e-05 - val_loss: 2.3320e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.5381e-05 - val_loss: 2.3686e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 7s 20us/sample - loss: 6.6436e-04 - val_loss: 5.6321e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 3.9982e-05 - val_loss: 3.2187e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 3.0729e-05 - val_loss: 2.9057e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.8763e-05 - val_loss: 2.7794e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.7571e-05 - val_loss: 2.9988e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.6651e-05 - val_loss: 2.5003e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.6327e-05 - val_loss: 2.4028e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.6379e-05 - val_loss: 2.3695e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.5846e-05 - val_loss: 2.3695e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.5264e-05 - val_loss: 2.6452e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 8s 22us/sample - loss: 0.0285 - val_loss: 2.7919e-04\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 1.3808e-04 - val_loss: 5.7457e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 4.4864e-05 - val_loss: 3.8472e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 3.5737e-05 - val_loss: 3.5047e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 6s 18us/sample - loss: 3.2059e-05 - val_loss: 3.0572e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.9738e-05 - val_loss: 2.8964e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.7978e-05 - val_loss: 2.6936e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.6538e-05 - val_loss: 2.6822e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.5570e-05 - val_loss: 2.4608e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.4896e-05 - val_loss: 2.4550e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 8s 22us/sample - loss: 6.5516e-04 - val_loss: 3.7307e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 7s 19us/sample - loss: 3.1962e-05 - val_loss: 2.8983e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 7s 19us/sample - loss: 2.9081e-05 - val_loss: 2.9142e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 7s 19us/sample - loss: 2.7897e-05 - val_loss: 3.2249e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 7s 19us/sample - loss: 2.8761e-05 - val_loss: 2.5707e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 7s 19us/sample - loss: 2.9700e-05 - val_loss: 3.3089e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 7s 19us/sample - loss: 2.8769e-05 - val_loss: 2.4076e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 7s 19us/sample - loss: 2.8990e-05 - val_loss: 2.3817e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 7s 19us/sample - loss: 2.8168e-05 - val_loss: 2.5139e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 7s 19us/sample - loss: 2.7588e-05 - val_loss: 2.7528e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 8s 22us/sample - loss: 5.1215e-04 - val_loss: 3.7803e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 3.2692e-05 - val_loss: 2.9330e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.9780e-05 - val_loss: 2.7589e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.8329e-05 - val_loss: 2.6270e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 7s 19us/sample - loss: 2.8614e-05 - val_loss: 2.4262e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.8711e-05 - val_loss: 2.5020e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.9794e-05 - val_loss: 2.4479e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.7298e-05 - val_loss: 3.4816e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.8010e-05 - val_loss: 3.0503e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.7464e-05 - val_loss: 2.3467e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 8s 22us/sample - loss: 0.0040 - val_loss: 7.2085e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 4.5031e-05 - val_loss: 3.4894e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 3.3202e-05 - val_loss: 3.0814e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 3.0628e-05 - val_loss: 2.9109e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.9558e-05 - val_loss: 2.8415e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.9984e-05 - val_loss: 4.2692e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 3.2173e-05 - val_loss: 3.0763e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 3.7174e-05 - val_loss: 3.2188e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 3.6505e-05 - val_loss: 2.6852e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 3.9949e-05 - val_loss: 2.7627e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 8s 21us/sample - loss: 9.6299e-04 - val_loss: 4.9228e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 3.5179e-05 - val_loss: 2.9781e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.9357e-05 - val_loss: 2.7649e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 7s 19us/sample - loss: 2.8044e-05 - val_loss: 3.0277e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.7263e-05 - val_loss: 2.6259e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.7245e-05 - val_loss: 2.7702e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.7850e-05 - val_loss: 2.5738e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.7857e-05 - val_loss: 3.0822e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.7453e-05 - val_loss: 2.8807e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.7643e-05 - val_loss: 2.4635e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 8s 21us/sample - loss: 7.3008e-04 - val_loss: 4.6688e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 3.5461e-05 - val_loss: 3.0089e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.9586e-05 - val_loss: 3.2663e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.8016e-05 - val_loss: 2.6996e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.7767e-05 - val_loss: 2.5728e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.7415e-05 - val_loss: 2.5131e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.8489e-05 - val_loss: 2.7286e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.7434e-05 - val_loss: 2.4271e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.7252e-05 - val_loss: 2.3428e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.7172e-05 - val_loss: 2.3766e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 9s 24us/sample - loss: 0.0045 - val_loss: 8.8546e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 5.6572e-05 - val_loss: 3.9826e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 3.5990e-05 - val_loss: 3.2688e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 6s 18us/sample - loss: 3.1464e-05 - val_loss: 3.0483e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.9377e-05 - val_loss: 2.8259e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.8390e-05 - val_loss: 2.9535e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.7481e-05 - val_loss: 2.6217e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.6799e-05 - val_loss: 2.6708e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.7089e-05 - val_loss: 2.4991e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.7477e-05 - val_loss: 2.5028e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 7s 20us/sample - loss: 7.1990e-04 - val_loss: 5.1988e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 3.5141e-05 - val_loss: 3.1146e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.9355e-05 - val_loss: 2.9726e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.7856e-05 - val_loss: 2.6452e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.7307e-05 - val_loss: 2.7530e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.6962e-05 - val_loss: 2.4841e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 2.6553e-05 - val_loss: 2.7344e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.7028e-05 - val_loss: 2.6242e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.7304e-05 - val_loss: 2.5188e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 2.5846e-05 - val_loss: 2.4185e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 9s 23us/sample - loss: 6.0412e-04 - val_loss: 4.8462e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 3.5857e-05 - val_loss: 3.1024e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.9730e-05 - val_loss: 2.7940e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 7s 19us/sample - loss: 2.7889e-05 - val_loss: 2.6360e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.6846e-05 - val_loss: 3.4782e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.6799e-05 - val_loss: 2.5344e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.6837e-05 - val_loss: 2.3893e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.7056e-05 - val_loss: 2.4547e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.5372e-05 - val_loss: 2.3974e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.6821e-05 - val_loss: 2.3395e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 8s 21us/sample - loss: 0.0467 - val_loss: 3.3585e-04\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.7682e-04 - val_loss: 2.0307e-04\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 6s 18us/sample - loss: 1.4740e-04 - val_loss: 9.1906e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 7.2390e-05 - val_loss: 5.6847e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 5.4023e-05 - val_loss: 5.0415e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 4.8495e-05 - val_loss: 4.4993e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 4.3141e-05 - val_loss: 3.9627e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 3.7652e-05 - val_loss: 3.4793e-05\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369243/369243 [==============================] - 6s 17us/sample - loss: 3.2837e-05 - val_loss: 3.0164e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.9673e-05 - val_loss: 2.7974e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 4s 12us/sample - loss: 7.4093e-04 - val_loss: 6.5890e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 3s 9us/sample - loss: 4.9236e-05 - val_loss: 3.7912e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 3s 9us/sample - loss: 3.5164e-05 - val_loss: 3.2750e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 3s 9us/sample - loss: 3.2092e-05 - val_loss: 3.0528e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 3s 9us/sample - loss: 3.0367e-05 - val_loss: 3.0119e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 3s 9us/sample - loss: 2.8747e-05 - val_loss: 2.7405e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 3s 9us/sample - loss: 2.7411e-05 - val_loss: 2.6128e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 3s 9us/sample - loss: 2.6425e-05 - val_loss: 2.6759e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 3s 9us/sample - loss: 2.5799e-05 - val_loss: 2.4511e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 3s 9us/sample - loss: 2.5224e-05 - val_loss: 2.4189e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 5s 12us/sample - loss: 0.0013 - val_loss: 7.2570e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 3s 9us/sample - loss: 5.5237e-05 - val_loss: 4.1882e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 3s 9us/sample - loss: 3.5843e-05 - val_loss: 3.1726e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 3s 9us/sample - loss: 3.0473e-05 - val_loss: 2.8981e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 3s 9us/sample - loss: 2.8618e-05 - val_loss: 2.7625e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 3s 9us/sample - loss: 2.7575e-05 - val_loss: 2.6496e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 3s 9us/sample - loss: 2.6477e-05 - val_loss: 2.6118e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 3s 9us/sample - loss: 2.5720e-05 - val_loss: 2.5296e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 3s 9us/sample - loss: 2.5313e-05 - val_loss: 2.7249e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 3s 9us/sample - loss: 2.4996e-05 - val_loss: 2.4123e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 4s 12us/sample - loss: 0.0019 - val_loss: 9.6803e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 3s 9us/sample - loss: 7.5568e-05 - val_loss: 5.8418e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 3s 9us/sample - loss: 4.7431e-05 - val_loss: 3.9159e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 3s 9us/sample - loss: 3.5944e-05 - val_loss: 3.3185e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 3s 9us/sample - loss: 3.2476e-05 - val_loss: 3.1158e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 3s 9us/sample - loss: 3.0761e-05 - val_loss: 2.9601e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 3s 9us/sample - loss: 2.9332e-05 - val_loss: 2.8667e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 3s 9us/sample - loss: 2.8116e-05 - val_loss: 2.7374e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 3s 9us/sample - loss: 2.6995e-05 - val_loss: 2.7202e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 3s 9us/sample - loss: 2.6083e-05 - val_loss: 2.8899e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 0.0011 - val_loss: 8.1027e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 5s 12us/sample - loss: 5.5840e-05 - val_loss: 4.0812e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 5s 13us/sample - loss: 3.6785e-05 - val_loss: 3.3936e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 5s 13us/sample - loss: 3.3062e-05 - val_loss: 3.1660e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 5s 13us/sample - loss: 3.1177e-05 - val_loss: 2.9899e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 5s 13us/sample - loss: 2.9478e-05 - val_loss: 2.8426e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 5s 13us/sample - loss: 2.8133e-05 - val_loss: 2.7004e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 5s 13us/sample - loss: 2.6963e-05 - val_loss: 2.6460e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 5s 13us/sample - loss: 2.6061e-05 - val_loss: 2.5104e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 5s 13us/sample - loss: 2.5313e-05 - val_loss: 2.6269e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 0.0010 - val_loss: 6.7148e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 5s 12us/sample - loss: 5.4286e-05 - val_loss: 4.3679e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 5s 13us/sample - loss: 3.8386e-05 - val_loss: 3.4500e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 5s 12us/sample - loss: 3.3041e-05 - val_loss: 3.1432e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 5s 12us/sample - loss: 3.0828e-05 - val_loss: 2.9693e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - ETA: 0s - loss: 2.9238e-0 - 4s 12us/sample - loss: 2.9240e-05 - val_loss: 2.8854e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 5s 12us/sample - loss: 2.7862e-05 - val_loss: 2.9331e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 5s 12us/sample - loss: 2.6616e-05 - val_loss: 2.6053e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 5s 12us/sample - loss: 2.5790e-05 - val_loss: 2.5650e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 5s 12us/sample - loss: 2.5120e-05 - val_loss: 2.4225e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 6s 15us/sample - loss: 0.0013 - val_loss: 9.3191e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 4s 12us/sample - loss: 7.1713e-05 - val_loss: 5.4930e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 4s 12us/sample - loss: 4.5675e-05 - val_loss: 3.8997e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 4s 12us/sample - loss: 3.6369e-05 - val_loss: 3.4030e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 4s 11us/sample - loss: 3.3278e-05 - val_loss: 3.2105e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 4s 12us/sample - loss: 3.1391e-05 - val_loss: 3.0220e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 4s 11us/sample - loss: 2.9767e-05 - val_loss: 2.8471e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 4s 12us/sample - loss: 2.8438e-05 - val_loss: 2.7911e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 4s 12us/sample - loss: 2.7083e-05 - val_loss: 2.5841e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 4s 12us/sample - loss: 2.5985e-05 - val_loss: 2.6206e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 6s 15us/sample - loss: 8.5355e-04 - val_loss: 7.1446e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 4s 12us/sample - loss: 5.4532e-05 - val_loss: 4.2056e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 4s 12us/sample - loss: 3.6989e-05 - val_loss: 3.3241e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 4s 12us/sample - loss: 3.1904e-05 - val_loss: 3.0677e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 4s 12us/sample - loss: 2.9524e-05 - val_loss: 2.8651e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 4s 12us/sample - loss: 2.7954e-05 - val_loss: 2.6932e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 4s 11us/sample - loss: 2.6685e-05 - val_loss: 2.6268e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 4s 12us/sample - loss: 2.5730e-05 - val_loss: 2.4719e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 4s 12us/sample - loss: 2.5117e-05 - val_loss: 2.6081e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 4s 12us/sample - loss: 2.4705e-05 - val_loss: 2.4087e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 6s 15us/sample - loss: 0.0025 - val_loss: 1.1179e-04\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 4s 11us/sample - loss: 8.3844e-05 - val_loss: 6.2132e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 4s 12us/sample - loss: 5.0010e-05 - val_loss: 4.0988e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 4s 12us/sample - loss: 3.7619e-05 - val_loss: 3.4558e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 4s 12us/sample - loss: 3.3801e-05 - val_loss: 3.2650e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 4s 12us/sample - loss: 3.1717e-05 - val_loss: 3.0321e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 4s 12us/sample - loss: 2.9933e-05 - val_loss: 3.0279e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 4s 12us/sample - loss: 2.8366e-05 - val_loss: 2.8543e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 4s 12us/sample - loss: 2.7086e-05 - val_loss: 2.5760e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 4s 12us/sample - loss: 2.6158e-05 - val_loss: 2.6095e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 5s 15us/sample - loss: 0.0011 - val_loss: 8.5963e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 4s 12us/sample - loss: 6.5313e-05 - val_loss: 4.8862e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 4s 12us/sample - loss: 4.0782e-05 - val_loss: 3.5374e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 4s 12us/sample - loss: 3.4034e-05 - val_loss: 3.2734e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 4s 11us/sample - loss: 3.2144e-05 - val_loss: 3.0962e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 4s 12us/sample - loss: 3.0673e-05 - val_loss: 2.9445e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 4s 12us/sample - loss: 2.9153e-05 - val_loss: 2.8444e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 4s 12us/sample - loss: 2.7749e-05 - val_loss: 2.6618e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 4s 12us/sample - loss: 2.6606e-05 - val_loss: 2.5858e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 4s 12us/sample - loss: 2.5857e-05 - val_loss: 3.1444e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 7s 20us/sample - loss: 0.0012 - val_loss: 6.5096e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 4.1922e-05 - val_loss: 3.1528e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 3.0538e-05 - val_loss: 2.8535e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 2.8488e-05 - val_loss: 2.7060e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 2.6968e-05 - val_loss: 2.5786e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 2.6769e-05 - val_loss: 3.8195e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 2.6109e-05 - val_loss: 2.4262e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 2.6254e-05 - val_loss: 2.5915e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 2.7092e-05 - val_loss: 2.6839e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 2.6242e-05 - val_loss: 3.4719e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 7s 20us/sample - loss: 8.7266e-04 - val_loss: 5.2703e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 3.8746e-05 - val_loss: 3.3169e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 3.2160e-05 - val_loss: 3.0596e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 2.9232e-05 - val_loss: 2.7476e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 6s 15us/sample - loss: 2.7784e-05 - val_loss: 2.7044e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 6s 15us/sample - loss: 2.7075e-05 - val_loss: 2.5259e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 6s 15us/sample - loss: 2.7385e-05 - val_loss: 2.4494e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 6s 15us/sample - loss: 2.6020e-05 - val_loss: 2.6380e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 2.6141e-05 - val_loss: 2.4041e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 2.6246e-05 - val_loss: 2.6839e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 0.0352 - val_loss: 1.9253e-04\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 5s 15us/sample - loss: 1.0929e-04 - val_loss: 6.6141e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 5s 15us/sample - loss: 5.5451e-05 - val_loss: 4.6105e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 5s 15us/sample - loss: 4.0524e-05 - val_loss: 3.6129e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 5s 15us/sample - loss: 3.4002e-05 - val_loss: 3.1682e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 5s 15us/sample - loss: 3.0614e-05 - val_loss: 2.9375e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 5s 15us/sample - loss: 2.8877e-05 - val_loss: 2.8032e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 5s 15us/sample - loss: 2.7906e-05 - val_loss: 2.7213e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 5s 15us/sample - loss: 2.7160e-05 - val_loss: 2.7486e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 5s 14us/sample - loss: 2.6675e-05 - val_loss: 2.7191e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 8.5668e-04 - val_loss: 5.3873e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 5s 14us/sample - loss: 3.7766e-05 - val_loss: 3.2152e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 5s 13us/sample - loss: 2.9614e-05 - val_loss: 2.8020e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 5s 13us/sample - loss: 2.7718e-05 - val_loss: 2.6324e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 5s 13us/sample - loss: 2.6430e-05 - val_loss: 2.5281e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 5s 13us/sample - loss: 2.5717e-05 - val_loss: 2.4485e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 5s 13us/sample - loss: 2.5423e-05 - val_loss: 2.4794e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 5s 13us/sample - loss: 2.5677e-05 - val_loss: 2.4414e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 5s 13us/sample - loss: 2.6358e-05 - val_loss: 2.4082e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 5s 13us/sample - loss: 2.4875e-05 - val_loss: 2.5287e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 7.4580e-04 - val_loss: 7.1843e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 5s 13us/sample - loss: 4.9879e-05 - val_loss: 3.6288e-05\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369243/369243 [==============================] - 5s 13us/sample - loss: 3.3480e-05 - val_loss: 3.1080e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 5s 13us/sample - loss: 3.0078e-05 - val_loss: 3.0593e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 5s 13us/sample - loss: 2.8009e-05 - val_loss: 2.6317e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 5s 13us/sample - loss: 2.6915e-05 - val_loss: 2.9630e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 5s 13us/sample - loss: 2.6963e-05 - val_loss: 2.4353e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 5s 13us/sample - loss: 2.6012e-05 - val_loss: 2.5832e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 5s 13us/sample - loss: 2.6471e-05 - val_loss: 2.8640e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 5s 13us/sample - loss: 2.5644e-05 - val_loss: 2.7066e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 9.5296e-04 - val_loss: 4.5525e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 5s 13us/sample - loss: 3.7029e-05 - val_loss: 3.2678e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 5s 13us/sample - loss: 3.1383e-05 - val_loss: 2.9601e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 5s 13us/sample - loss: 2.9459e-05 - val_loss: 3.0380e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 5s 13us/sample - loss: 2.8262e-05 - val_loss: 2.8205e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 5s 12us/sample - loss: 2.7389e-05 - val_loss: 2.6356e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 5s 13us/sample - loss: 2.7112e-05 - val_loss: 2.5107e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 5s 13us/sample - loss: 2.6516e-05 - val_loss: 3.0413e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 5s 13us/sample - loss: 2.6246e-05 - val_loss: 2.4271e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 5s 13us/sample - loss: 2.5620e-05 - val_loss: 2.3805e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 7s 19us/sample - loss: 8.4654e-04 - val_loss: 6.2382e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 5s 15us/sample - loss: 4.1994e-05 - val_loss: 3.3138e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 5s 15us/sample - loss: 3.1695e-05 - val_loss: 2.9698e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 5s 15us/sample - loss: 2.9131e-05 - val_loss: 2.8150e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 6s 16us/sample - loss: 2.7339e-05 - val_loss: 2.6003e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 5s 15us/sample - loss: 2.6077e-05 - val_loss: 2.4762e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 5s 14us/sample - loss: 2.5296e-05 - val_loss: 2.7484e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 5s 15us/sample - loss: 2.5448e-05 - val_loss: 2.4079e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 5s 15us/sample - loss: 2.5014e-05 - val_loss: 2.4911e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 5s 15us/sample - loss: 2.5187e-05 - val_loss: 2.3021e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 0.0010 - val_loss: 7.5363e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 6s 15us/sample - loss: 5.2853e-05 - val_loss: 3.9605e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 5s 15us/sample - loss: 3.5888e-05 - val_loss: 3.2813e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 5s 15us/sample - loss: 3.2118e-05 - val_loss: 3.1227e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 5s 15us/sample - loss: 2.9656e-05 - val_loss: 2.7699e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 5s 15us/sample - loss: 2.7429e-05 - val_loss: 2.6211e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 5s 15us/sample - loss: 2.6135e-05 - val_loss: 2.4761e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 5s 15us/sample - loss: 2.5843e-05 - val_loss: 2.4285e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 5s 15us/sample - loss: 2.5093e-05 - val_loss: 2.8315e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 5s 14us/sample - loss: 2.5077e-05 - val_loss: 2.9730e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 0.0055 - val_loss: 1.7323e-04\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 5s 14us/sample - loss: 8.6243e-05 - val_loss: 4.1630e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 5s 14us/sample - loss: 3.5785e-05 - val_loss: 3.4086e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 5s 13us/sample - loss: 3.0857e-05 - val_loss: 2.9397e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 5s 13us/sample - loss: 2.8730e-05 - val_loss: 2.7686e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 5s 13us/sample - loss: 2.7184e-05 - val_loss: 2.7270e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 5s 13us/sample - loss: 2.6030e-05 - val_loss: 2.5875e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 5s 13us/sample - loss: 2.5253e-05 - val_loss: 2.4978e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 5s 13us/sample - loss: 2.4835e-05 - val_loss: 2.4253e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 5s 13us/sample - loss: 2.4498e-05 - val_loss: 2.4557e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 8s 21us/sample - loss: 9.4238e-04 - val_loss: 4.8808e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 3.5485e-05 - val_loss: 3.0932e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.9841e-05 - val_loss: 2.8979e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.8045e-05 - val_loss: 2.7969e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.7459e-05 - val_loss: 2.6800e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.7705e-05 - val_loss: 3.6112e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.7849e-05 - val_loss: 2.5413e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.8887e-05 - val_loss: 3.2806e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.7119e-05 - val_loss: 2.4516e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.6971e-05 - val_loss: 2.3411e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 8s 21us/sample - loss: 6.6564e-04 - val_loss: 3.9453e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 3.3611e-05 - val_loss: 3.0825e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 3.0042e-05 - val_loss: 2.9193e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.8161e-05 - val_loss: 2.8245e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.7483e-05 - val_loss: 2.5067e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.7522e-05 - val_loss: 2.4443e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.7840e-05 - val_loss: 2.3635e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.7247e-05 - val_loss: 2.4892e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.7125e-05 - val_loss: 4.4201e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.6302e-05 - val_loss: 3.1565e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 8s 21us/sample - loss: 0.0027 - val_loss: 7.0883e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 4.8306e-05 - val_loss: 3.8077e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 3.6268e-05 - val_loss: 3.3099e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 3.2571e-05 - val_loss: 3.2139e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 3.1809e-05 - val_loss: 2.9905e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 3.2519e-05 - val_loss: 2.8313e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 3.5340e-05 - val_loss: 3.0621e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 3.8825e-05 - val_loss: 4.4796e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 3.6579e-05 - val_loss: 2.8897e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 3.6863e-05 - val_loss: 3.4994e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 6.5806e-04 - val_loss: 4.2134e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 5s 13us/sample - loss: 3.4907e-05 - val_loss: 3.3462e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 5s 13us/sample - loss: 3.0377e-05 - val_loss: 2.9454e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 5s 14us/sample - loss: 2.8527e-05 - val_loss: 2.7938e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 5s 14us/sample - loss: 2.7571e-05 - val_loss: 2.5574e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 5s 14us/sample - loss: 2.7383e-05 - val_loss: 2.5425e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 5s 14us/sample - loss: 2.6593e-05 - val_loss: 2.4397e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 5s 14us/sample - loss: 2.6875e-05 - val_loss: 2.7612e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 5s 14us/sample - loss: 2.6092e-05 - val_loss: 2.5999e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 5s 14us/sample - loss: 2.6449e-05 - val_loss: 2.7556e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 8s 21us/sample - loss: 5.4719e-04 - val_loss: 3.5310e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 3.2388e-05 - val_loss: 3.0121e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.9567e-05 - val_loss: 3.1696e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.8206e-05 - val_loss: 2.9067e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.7662e-05 - val_loss: 2.6804e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 6s 18us/sample - loss: 2.6877e-05 - val_loss: 2.4834e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 6s 18us/sample - loss: 2.7117e-05 - val_loss: 2.8709e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 6s 18us/sample - loss: 2.6772e-05 - val_loss: 2.4259e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 2.7017e-05 - val_loss: 2.6318e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.6282e-05 - val_loss: 2.3396e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 8s 21us/sample - loss: 0.0336 - val_loss: 1.7508e-04\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 1.1512e-04 - val_loss: 7.7704e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 6.4940e-05 - val_loss: 5.5318e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 5.0569e-05 - val_loss: 4.4285e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 3.9796e-05 - val_loss: 3.5937e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 3.3132e-05 - val_loss: 3.0839e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.9886e-05 - val_loss: 2.8530e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.8179e-05 - val_loss: 2.7088e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.7019e-05 - val_loss: 2.6052e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 6s 17us/sample - loss: 2.6176e-05 - val_loss: 2.5597e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 0.0010 - val_loss: 6.8027e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 5s 15us/sample - loss: 4.5143e-05 - val_loss: 3.4539e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 5s 15us/sample - loss: 3.2105e-05 - val_loss: 3.0294e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 5s 15us/sample - loss: 2.9796e-05 - val_loss: 2.8766e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 5s 14us/sample - loss: 2.8431e-05 - val_loss: 2.7706e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 6s 15us/sample - loss: 2.7241e-05 - val_loss: 2.6242e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 5s 15us/sample - loss: 2.6684e-05 - val_loss: 2.4722e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 5s 15us/sample - loss: 2.6721e-05 - val_loss: 2.4251e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 5s 15us/sample - loss: 2.5283e-05 - val_loss: 2.4424e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 5s 15us/sample - loss: 2.5802e-05 - val_loss: 2.3508e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 7s 19us/sample - loss: 7.2843e-04 - val_loss: 4.1967e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 6s 15us/sample - loss: 3.3491e-05 - val_loss: 3.0704e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 6s 15us/sample - loss: 2.8997e-05 - val_loss: 2.7450e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 6s 15us/sample - loss: 2.7229e-05 - val_loss: 2.7490e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 6s 15us/sample - loss: 2.6503e-05 - val_loss: 2.4775e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 6s 15us/sample - loss: 2.6502e-05 - val_loss: 2.5579e-05\n",
      "Epoch 7/10\n",
      "369243/369243 [==============================] - 5s 14us/sample - loss: 2.5863e-05 - val_loss: 3.0280e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 6s 15us/sample - loss: 2.6049e-05 - val_loss: 2.7003e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 6s 15us/sample - loss: 2.5517e-05 - val_loss: 2.4042e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 6s 15us/sample - loss: 2.5712e-05 - val_loss: 2.3522e-05\n",
      "Train on 369243 samples, validate on 41027 samples\n",
      "Epoch 1/10\n",
      "369243/369243 [==============================] - 7s 18us/sample - loss: 7.4917e-04 - val_loss: 5.9149e-05\n",
      "Epoch 2/10\n",
      "369243/369243 [==============================] - 5s 15us/sample - loss: 4.9635e-05 - val_loss: 4.0944e-05\n",
      "Epoch 3/10\n",
      "369243/369243 [==============================] - 5s 15us/sample - loss: 3.8023e-05 - val_loss: 3.4087e-05\n",
      "Epoch 4/10\n",
      "369243/369243 [==============================] - 5s 15us/sample - loss: 3.2817e-05 - val_loss: 2.9649e-05\n",
      "Epoch 5/10\n",
      "369243/369243 [==============================] - 5s 15us/sample - loss: 3.0329e-05 - val_loss: 2.9412e-05\n",
      "Epoch 6/10\n",
      "369243/369243 [==============================] - 5s 15us/sample - loss: 2.9022e-05 - val_loss: 2.8253e-05\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369243/369243 [==============================] - 5s 15us/sample - loss: 2.8230e-05 - val_loss: 2.6199e-05\n",
      "Epoch 8/10\n",
      "369243/369243 [==============================] - 5s 14us/sample - loss: 2.7234e-05 - val_loss: 2.6716e-05\n",
      "Epoch 9/10\n",
      "369243/369243 [==============================] - 5s 14us/sample - loss: 2.6570e-05 - val_loss: 2.9635e-05\n",
      "Epoch 10/10\n",
      "369243/369243 [==============================] - 5s 15us/sample - loss: 2.6202e-05 - val_loss: 2.5364e-05\n",
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_54 (LSTM)               (None, 1, 64)             20480     \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 1, 16)             1040      \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 1, 1)              17        \n",
      "=================================================================\n",
      "Total params: 21,537\n",
      "Trainable params: 21,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 410270 samples, validate on 45586 samples\n",
      "Epoch 1/10\n",
      "410270/410270 [==============================] - 7s 18us/sample - loss: 0.0053 - val_loss: 1.1524e-04\n",
      "Epoch 2/10\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 7.2123e-05 - val_loss: 4.3066e-05\n",
      "Epoch 3/10\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 3.5808e-05 - val_loss: 3.2578e-05\n",
      "Epoch 4/10\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 3.1126e-05 - val_loss: 3.0326e-05\n",
      "Epoch 5/10\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.9340e-05 - val_loss: 2.8678e-05\n",
      "Epoch 6/10\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.8131e-05 - val_loss: 2.7543e-05\n",
      "Epoch 7/10\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.7119e-05 - val_loss: 2.7290e-05\n",
      "Epoch 8/10\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.6324e-05 - val_loss: 2.5801e-05\n",
      "Epoch 9/10\n",
      "410270/410270 [==============================] - 6s 14us/sample - loss: 2.5591e-05 - val_loss: 2.7844e-05\n",
      "Epoch 10/10\n",
      "410270/410270 [==============================] - 5s 13us/sample - loss: 2.5274e-05 - val_loss: 2.5705e-05\n"
     ]
    }
   ],
   "source": [
    "# in the github file I have cleared the output of this cell\n",
    "pred = predict('Mainz', 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimal_parameters': {'lstm_units': 64,\n",
       "  'hidden_dense_layers': 1,\n",
       "  'dense_units': 16,\n",
       "  'act_fct': 'linear'},\n",
       " 'train_loss': 2.5274178315304524e-05,\n",
       " 'test_loss': 2.570485759481075e-05,\n",
       " 'last_observed_city_level': 534.0,\n",
       " 'the_prediction': array([[[516.04675]]], dtype=float32)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
